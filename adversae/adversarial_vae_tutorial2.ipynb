{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a67261a",
   "metadata": {},
   "source": [
    "# Adversarial Attacks on Variational Autoencoders\n",
    "\n",
    "This notebook demonstrates how to engineer adversarial attacks against a VAE using MNIST dataset with LeNet-style encoder/decoder and 2D latent space.\n",
    "\n",
    "## Key Concepts:\n",
    "- **FGSM (Fast Gradient Sign Method)**: Single-step attack using gradient sign\n",
    "- **PGD (Projected Gradient Descent)**: Multi-step iterative attack\n",
    "- **Latent Space Attack**: Attack in the encoded latent representation\n",
    "- **VAE Vulnerabilities**: How reconstruction and regularization losses affect robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d676d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision numpy matplotlib tqdm psutil\n",
    "\n",
    "# Install GPU monitoring tools (optional - will fallback to nvidia-smi if not available)\n",
    "try:\n",
    "    !pip install nvidia-ml-py\n",
    "    print(\"‚úì nvidia-ml-py installed for efficient GPU monitoring\")\n",
    "except:\n",
    "    print(\"‚ö† nvidia-ml-py not available, will use nvidia-smi fallback\")\n",
    "\n",
    "# Check if nvidia-smi is available\n",
    "import subprocess\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi', '--version'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úì nvidia-smi available for GPU monitoring\")\n",
    "    else:\n",
    "        print(\"‚ö† nvidia-smi not available - GPU monitoring will show zeros\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö† nvidia-smi not found - GPU monitoring will show zeros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25cd069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e1ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check if GPU is available and print basic info\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"No GPU available - using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20929af",
   "metadata": {},
   "source": [
    "## 1. Define VAE Architecture with LeNet-style Encoder/Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetEncoder(nn.Module):\n",
    "    \"\"\"LeNet-style encoder for VAE\"\"\"\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super(LeNetEncoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Convolutional layers (LeNet-style)\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)  # 28x28 -> 28x28\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # 28x28 -> 14x14\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)  # 14x14 -> 10x10\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # 10x10 -> 5x5\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        \n",
    "        # Output layers for mean and log variance\n",
    "        self.fc_mu = nn.Linear(84, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(84, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Output mean and log variance\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5158fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetDecoder(nn.Module):\n",
    "    \"\"\"LeNet-style decoder for VAE\"\"\"\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super(LeNetDecoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(latent_dim, 84)\n",
    "        self.fc2 = nn.Linear(84, 120)\n",
    "        self.fc3 = nn.Linear(120, 16 * 5 * 5)\n",
    "        \n",
    "        # Transposed convolutional layers (reverse of encoder)\n",
    "        self.deconv1 = nn.ConvTranspose2d(16, 6, kernel_size=5, stride=2, padding=2, output_padding=1)  # 5x5 -> 10x10\n",
    "        self.deconv2 = nn.ConvTranspose2d(6, 1, kernel_size=5, stride=2, padding=2, output_padding=1)   # 10x10 -> 20x20\n",
    "        # Add padding to get from 20x20 to 28x28\n",
    "        self.final_conv = nn.ConvTranspose2d(1, 1, kernel_size=9, stride=1, padding=0)  # 20x20 -> 28x28\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(z))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        # Reshape to feature maps\n",
    "        x = x.view(-1, 16, 5, 5)\n",
    "        \n",
    "        # Transposed convolutional layers\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = torch.sigmoid(self.final_conv(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7341240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"Variational Autoencoder with LeNet-style architecture\"\"\"\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = LeNetEncoder(latent_dim)\n",
    "        self.decoder = LeNetDecoder(latent_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Reparameterization trick\"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decoder(z)\n",
    "        return recon_x, mu, logvar\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input to latent space\"\"\"\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return self.reparameterize(mu, logvar)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode from latent space\"\"\"\n",
    "        return self.decoder(z)\n",
    "\n",
    "def vae_loss(recon_x, x, mu, logvar, beta=1.0):\n",
    "    \"\"\"VAE loss function with KL divergence\"\"\"\n",
    "    # Reconstruction loss\n",
    "    recon_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    \n",
    "    # KL divergence loss\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return recon_loss + beta * kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667618d6",
   "metadata": {},
   "source": [
    "## 2. Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980fbb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Visualize some samples\n",
    "def show_samples(loader, num_samples=8):\n",
    "    data_iter = iter(loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(12, 2))\n",
    "    for i in range(num_samples):\n",
    "        axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Label: {labels[i]}')\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90f158",
   "metadata": {},
   "source": [
    "## 3. Train the VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, train_loader, epochs=10, lr=1e-3, beta=1.0):\n",
    "    \"\"\"Train the VAE model\"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    print(\"Training VAE...\")\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = vae_loss(recon_batch, data, mu, logvar, beta)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_loader.dataset)\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return train_losses\n",
    "\n",
    "# Initialize and train model\n",
    "model = VAE(latent_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the VAE model\n",
    "train_losses = train_vae(model, train_loader, epochs=10, beta=1.0)\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, 'b-', linewidth=2, marker='o')\n",
    "plt.title('VAE Training Loss', fontsize=14)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print training summary\n",
    "final_loss = train_losses[-1]\n",
    "initial_loss = train_losses[0]\n",
    "improvement = initial_loss - final_loss\n",
    "\n",
    "print(f\"\\nüìä Training Summary:\")\n",
    "print(f\"Initial Loss: {initial_loss:.6f}\")\n",
    "print(f\"Final Loss: {final_loss:.6f}\")\n",
    "print(f\"Total Improvement: {improvement:.6f}\")\n",
    "print(f\"Improvement %: {(improvement/initial_loss)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d034b3",
   "metadata": {},
   "source": [
    "## 3.5 VAE Quality Assessment\n",
    "\n",
    "Before proceeding with adversarial attacks, let's thoroughly evaluate the trained VAE to ensure it has learned meaningful representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e07fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_vae_reconstructions(model, test_loader, device, num_samples=10):\n",
    "    \"\"\"\n",
    "    Evaluate VAE reconstruction quality on random test samples\n",
    "    Shows original vs reconstruction side by side with reconstruction errors\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get random test samples\n",
    "    test_iter = iter(test_loader)\n",
    "    test_data, test_labels = next(test_iter)\n",
    "    \n",
    "    # Select random samples\n",
    "    indices = torch.randperm(test_data.size(0))[:num_samples]\n",
    "    sample_data = test_data[indices].to(device)\n",
    "    sample_labels = test_labels[indices]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get reconstructions\n",
    "        recon_data, mu, logvar = model(sample_data)\n",
    "        \n",
    "        # Calculate reconstruction errors\n",
    "        recon_errors = F.mse_loss(recon_data, sample_data, reduction='none')\n",
    "        recon_errors = recon_errors.view(recon_errors.size(0), -1).mean(dim=1)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(3, num_samples, figsize=(num_samples*2, 6))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original image\n",
    "        axes[0, i].imshow(sample_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "        axes[0, i].set_title(f'Original\\nDigit: {sample_labels[i].item()}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Reconstructed image\n",
    "        axes[1, i].imshow(recon_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "        axes[1, i].set_title(f'Reconstruction\\nMSE: {recon_errors[i].item():.4f}')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Difference (amplified)\n",
    "        diff = (sample_data[i] - recon_data[i]).detach().cpu().squeeze()\n",
    "        axes[2, i].imshow(diff * 5, cmap='RdBu', vmin=-1, vmax=1)\n",
    "        axes[2, i].set_title(f'Difference (√ó5)')\n",
    "        axes[2, i].axis('off')\n",
    "    \n",
    "    # Add row labels\n",
    "    axes[0, 0].set_ylabel('Original', rotation=90, labelpad=40, fontsize=12, ha='center')\n",
    "    axes[1, 0].set_ylabel('Reconstruction', rotation=90, labelpad=40, fontsize=12, ha='center')\n",
    "    axes[2, 0].set_ylabel('Difference', rotation=90, labelpad=40, fontsize=12, ha='center')\n",
    "    \n",
    "    plt.suptitle(f'VAE Reconstruction Quality Assessment ({num_samples} Random Samples)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    avg_error = recon_errors.mean().item()\n",
    "    std_error = recon_errors.std().item()\n",
    "    min_error = recon_errors.min().item()\n",
    "    max_error = recon_errors.max().item()\n",
    "    \n",
    "    print(f\"\\nüìä Reconstruction Statistics:\")\n",
    "    print(f\"Average MSE: {avg_error:.6f}\")\n",
    "    print(f\"Std Dev MSE: {std_error:.6f}\")\n",
    "    print(f\"Min MSE: {min_error:.6f}\")\n",
    "    print(f\"Max MSE: {max_error:.6f}\")\n",
    "    \n",
    "    # Analyze latent space statistics\n",
    "    with torch.no_grad():\n",
    "        mu_mean = mu.mean(dim=0)\n",
    "        mu_std = mu.std(dim=0)\n",
    "        latent_norm = torch.norm(mu, dim=1).mean()\n",
    "    \n",
    "    print(f\"\\nüß† Latent Space Statistics:\")\n",
    "    print(f\"Latent dimensions: {model.latent_dim}\")\n",
    "    print(f\"Mean latent values: [{mu_mean[0].item():.4f}, {mu_mean[1].item():.4f}]\")\n",
    "    print(f\"Std latent values: [{mu_std[0].item():.4f}, {mu_std[1].item():.4f}]\")\n",
    "    print(f\"Average latent norm: {latent_norm.item():.4f}\")\n",
    "    \n",
    "    return recon_errors, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space_grid(model, device, grid_size=15, latent_range=3):\n",
    "    \"\"\"\n",
    "    Generate and visualize a grid of samples from the latent space\n",
    "    This shows what the VAE has learned to generate across the latent space\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a grid of points in latent space\n",
    "    x = np.linspace(-latent_range, latent_range, grid_size)\n",
    "    y = np.linspace(-latent_range, latent_range, grid_size)\n",
    "    \n",
    "    # Create meshgrid\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    \n",
    "    # Flatten the grid\n",
    "    grid_points = np.column_stack([xx.ravel(), yy.ravel()])\n",
    "    \n",
    "    # Convert to tensor\n",
    "    latent_samples = torch.FloatTensor(grid_points).to(device)\n",
    "    \n",
    "    # Generate images from latent samples\n",
    "    with torch.no_grad():\n",
    "        generated_images = model.decoder(latent_samples)\n",
    "    \n",
    "    # Create the visualization\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    \n",
    "    # Create a large image by concatenating generated samples\n",
    "    img_size = 28  # MNIST image size\n",
    "    full_image = np.zeros((grid_size * img_size, grid_size * img_size))\n",
    "    \n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            idx = i * grid_size + j\n",
    "            img = generated_images[idx].cpu().squeeze().numpy()\n",
    "            \n",
    "            # Place the image in the correct position\n",
    "            start_row = i * img_size\n",
    "            end_row = start_row + img_size\n",
    "            start_col = j * img_size\n",
    "            end_col = start_col + img_size\n",
    "            \n",
    "            full_image[start_row:end_row, start_col:end_col] = img\n",
    "    \n",
    "    # Display the full image\n",
    "    ax.imshow(full_image, cmap='gray')\n",
    "    ax.set_title(f'Latent Space Manifold Visualization ({grid_size}√ó{grid_size} grid)\\n'\n",
    "                f'Range: [{-latent_range}, {latent_range}] in both dimensions', fontsize=14)\n",
    "    \n",
    "    # Add coordinate labels\n",
    "    tick_positions = np.arange(0, grid_size * img_size, img_size) + img_size // 2\n",
    "    tick_labels = [f'{val:.1f}' for val in x]\n",
    "    \n",
    "    ax.set_xticks(tick_positions[::3])  # Show every 3rd tick to avoid crowding\n",
    "    ax.set_yticks(tick_positions[::3])\n",
    "    ax.set_xticklabels(tick_labels[::3])\n",
    "    ax.set_yticklabels(tick_labels[::3])\n",
    "    \n",
    "    ax.set_xlabel('Latent Dimension 1', fontsize=12)\n",
    "    ax.set_ylabel('Latent Dimension 2', fontsize=12)\n",
    "    \n",
    "    # Add grid lines for better visualization\n",
    "    for i in range(1, grid_size):\n",
    "        ax.axhline(y=i * img_size, color='red', alpha=0.3, linewidth=0.5)\n",
    "        ax.axvline(x=i * img_size, color='red', alpha=0.3, linewidth=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Also create a smaller focused view around the center\n",
    "    center_range = 2\n",
    "    center_grid = 10\n",
    "    \n",
    "    # Create centered grid\n",
    "    x_center = np.linspace(-center_range, center_range, center_grid)\n",
    "    y_center = np.linspace(-center_range, center_range, center_grid)\n",
    "    xx_center, yy_center = np.meshgrid(x_center, y_center)\n",
    "    grid_points_center = np.column_stack([xx_center.ravel(), yy_center.ravel()])\n",
    "    latent_samples_center = torch.FloatTensor(grid_points_center).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_images_center = model.decoder(latent_samples_center)\n",
    "    \n",
    "    # Create focused visualization\n",
    "    fig, axes = plt.subplots(center_grid, center_grid, figsize=(10, 10))\n",
    "    \n",
    "    for i in range(center_grid):\n",
    "        for j in range(center_grid):\n",
    "            idx = i * center_grid + j\n",
    "            img = generated_images_center[idx].cpu().squeeze().numpy()\n",
    "            \n",
    "            axes[i, j].imshow(img, cmap='gray')\n",
    "            axes[i, j].axis('off')\n",
    "            \n",
    "            # Add coordinate labels on border\n",
    "            if i == 0:  # Top row\n",
    "                axes[i, j].set_title(f'{x_center[j]:.1f}', fontsize=8)\n",
    "            if j == 0:  # Left column\n",
    "                axes[i, j].set_ylabel(f'{y_center[i]:.1f}', fontsize=8)\n",
    "    \n",
    "    plt.suptitle(f'Focused Latent Space View (Center Region ¬±{center_range})', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"üé® Generated {grid_size*grid_size} images from latent space grid\")\n",
    "    print(f\"üìç Latent range: [{-latent_range}, {latent_range}]\")\n",
    "    print(f\"üîç Focused view range: [{-center_range}, {center_range}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate VAE Reconstruction Quality\n",
    "print(\"üîç Evaluating VAE Reconstruction Quality...\")\n",
    "recon_errors, latent_samples = evaluate_vae_reconstructions(model, test_loader, device, num_samples=10)\n",
    "\n",
    "# Check if the model has learned reasonable reconstructions\n",
    "avg_error = recon_errors.mean().item()\n",
    "if avg_error > 0.1:\n",
    "    print(f\"‚ö†Ô∏è  WARNING: High reconstruction error ({avg_error:.4f})\")\n",
    "    print(\"   Consider training for more epochs or adjusting hyperparameters\")\n",
    "elif avg_error > 0.05:\n",
    "    print(f\"‚ö†Ô∏è  MODERATE: Reconstruction error is moderate ({avg_error:.4f})\")\n",
    "    print(\"   VAE quality is acceptable but could be improved\")\n",
    "else:\n",
    "    print(f\"‚úÖ GOOD: Low reconstruction error ({avg_error:.4f})\")\n",
    "    print(\"   VAE has learned good reconstructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af18c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Latent Space Grid Visualization\n",
    "print(\"üé® Generating latent space manifold visualization...\")\n",
    "plot_latent_space_grid(model, device, grid_size=15, latent_range=3)\n",
    "\n",
    "# Additional analysis: Check latent space coverage\n",
    "with torch.no_grad():\n",
    "    # Sample from test set to see latent distribution\n",
    "    test_iter = iter(test_loader)\n",
    "    test_batch, test_batch_labels = next(test_iter)\n",
    "    test_batch = test_batch[:100].to(device)  # Use 100 samples\n",
    "    \n",
    "    mu_batch, _ = model.encoder(test_batch)\n",
    "    \n",
    "    # Calculate latent space statistics\n",
    "    latent_mean = mu_batch.mean(dim=0)\n",
    "    latent_std = mu_batch.std(dim=0)\n",
    "    latent_range_actual = [\n",
    "        (mu_batch[:, 0].min().item(), mu_batch[:, 0].max().item()),\n",
    "        (mu_batch[:, 1].min().item(), mu_batch[:, 1].max().item())\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüìä Latent Space Coverage Analysis:\")\n",
    "    print(f\"Dimension 1 - Mean: {latent_mean[0].item():.3f}, Std: {latent_std[0].item():.3f}\")\n",
    "    print(f\"Dimension 1 - Range: [{latent_range_actual[0][0]:.3f}, {latent_range_actual[0][1]:.3f}]\")\n",
    "    print(f\"Dimension 2 - Mean: {latent_mean[1].item():.3f}, Std: {latent_std[1].item():.3f}\")\n",
    "    print(f\"Dimension 2 - Range: [{latent_range_actual[1][0]:.3f}, {latent_range_actual[1][1]:.3f}]\")\n",
    "    \n",
    "    # Check if latent space is being utilized effectively\n",
    "    max_range = max(latent_range_actual[0][1] - latent_range_actual[0][0],\n",
    "                   latent_range_actual[1][1] - latent_range_actual[1][0])\n",
    "    \n",
    "    if max_range < 2:\n",
    "        print(\"‚ö†Ô∏è  Latent space utilization is limited - consider reducing regularization (Œ≤)\")\n",
    "    elif max_range > 6:\n",
    "        print(\"‚ö†Ô∏è  Latent space is very spread out - consider increasing regularization (Œ≤)\")\n",
    "    else:\n",
    "        print(\"‚úÖ Latent space utilization looks good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f721d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Sufficiency Assessment\n",
    "print(\"\\nüéØ VAE Training Sufficiency Assessment:\")\n",
    "\n",
    "# Calculate final training loss\n",
    "final_loss = train_losses[-1] if train_losses else float('inf')\n",
    "print(f\"Final training loss: {final_loss:.6f}\")\n",
    "\n",
    "# Assess training quality based on multiple metrics\n",
    "assessment_score = 0\n",
    "recommendations = []\n",
    "\n",
    "# 1. Reconstruction error assessment\n",
    "avg_recon_error = recon_errors.mean().item()\n",
    "if avg_recon_error < 0.05:\n",
    "    assessment_score += 3\n",
    "    print(\"‚úÖ Reconstruction quality: EXCELLENT\")\n",
    "elif avg_recon_error < 0.1:\n",
    "    assessment_score += 2\n",
    "    print(\"‚úÖ Reconstruction quality: GOOD\")\n",
    "elif avg_recon_error < 0.15:\n",
    "    assessment_score += 1\n",
    "    print(\"‚ö†Ô∏è  Reconstruction quality: MODERATE\")\n",
    "    recommendations.append(\"Consider training for more epochs\")\n",
    "else:\n",
    "    print(\"‚ùå Reconstruction quality: POOR\")\n",
    "    recommendations.append(\"Increase training epochs significantly\")\n",
    "\n",
    "# 2. Training loss convergence\n",
    "if len(train_losses) >= 3:\n",
    "    loss_improvement = train_losses[0] - train_losses[-1]\n",
    "    loss_stability = abs(train_losses[-1] - train_losses[-2])\n",
    "    \n",
    "    if loss_improvement > 0.01 and loss_stability < 0.001:\n",
    "        assessment_score += 3\n",
    "        print(\"‚úÖ Training convergence: EXCELLENT\")\n",
    "    elif loss_improvement > 0.005:\n",
    "        assessment_score += 2\n",
    "        print(\"‚úÖ Training convergence: GOOD\")\n",
    "    elif loss_improvement > 0.001:\n",
    "        assessment_score += 1\n",
    "        print(\"‚ö†Ô∏è  Training convergence: MODERATE\")\n",
    "        recommendations.append(\"Train for more epochs for better convergence\")\n",
    "    else:\n",
    "        print(\"‚ùå Training convergence: POOR\")\n",
    "        recommendations.append(\"Training may need more epochs or different hyperparameters\")\n",
    "\n",
    "# 3. Latent space utilization\n",
    "if max_range > 1.5 and max_range < 5:\n",
    "    assessment_score += 2\n",
    "    print(\"‚úÖ Latent space utilization: GOOD\")\n",
    "elif max_range > 0.8:\n",
    "    assessment_score += 1\n",
    "    print(\"‚ö†Ô∏è  Latent space utilization: MODERATE\")\n",
    "else:\n",
    "    print(\"‚ùå Latent space utilization: POOR\")\n",
    "    recommendations.append(\"Adjust Œ≤ parameter for better latent space usage\")\n",
    "\n",
    "# Overall assessment\n",
    "total_score = assessment_score\n",
    "max_score = 8\n",
    "\n",
    "print(f\"\\nüìä Overall VAE Quality Score: {total_score}/{max_score}\")\n",
    "\n",
    "if total_score >= 7:\n",
    "    print(\"üéâ EXCELLENT: VAE is well-trained and ready for adversarial attacks!\")\n",
    "elif total_score >= 5:\n",
    "    print(\"üëç GOOD: VAE quality is acceptable for adversarial attack analysis\")\n",
    "elif total_score >= 3:\n",
    "    print(\"‚ö†Ô∏è  MODERATE: VAE could benefit from additional training\")\n",
    "else:\n",
    "    print(\"‚ùå POOR: Consider retraining the VAE with different parameters\")\n",
    "\n",
    "if recommendations:\n",
    "    print(f\"\\nüí° Recommendations:\")\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"   {i}. {rec}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üìà If you want to improve the VAE, consider:\")\n",
    "print(\"   ‚Ä¢ Increasing epochs to 20-50\")\n",
    "print(\"   ‚Ä¢ Adjusting Œ≤ (try 0.5 for less regularization)\")\n",
    "print(\"   ‚Ä¢ Using a different learning rate (try 1e-4)\")\n",
    "print(\"   ‚Ä¢ Adding batch normalization or dropout\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56488eb3",
   "metadata": {},
   "source": [
    "## 4. Visualize Latent Space (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(model, test_loader, device, num_samples=2000):\n",
    "    \"\"\"Plot the 2D latent space representation\"\"\"\n",
    "    model.eval()\n",
    "    latents = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data = data.to(device)\n",
    "            mu, _ = model.encoder(data)\n",
    "            latents.append(mu.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "            \n",
    "            if len(latents) * data.size(0) >= num_samples:\n",
    "                break\n",
    "    \n",
    "    latents = np.concatenate(latents, axis=0)[:num_samples]\n",
    "    labels = np.concatenate(labels, axis=0)[:num_samples]\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter = plt.scatter(latents[:, 0], latents[:, 1], c=labels, cmap='tab10', alpha=0.6)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title('2D Latent Space Representation (Color = Digit Class)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return latents, labels\n",
    "\n",
    "latents, labels = plot_latent_space(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e133d24",
   "metadata": {},
   "source": [
    "## 5. Implement Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialAttacks:\n",
    "    \"\"\"Class containing various adversarial attack methods for VAEs\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def fgsm_attack(model, data, target, epsilon):\n",
    "        \"\"\"\n",
    "        Fast Gradient Sign Method (FGSM) attack\n",
    "        \n",
    "        Args:\n",
    "            model: VAE model\n",
    "            data: input data\n",
    "            target: target data (for reconstruction loss)\n",
    "            epsilon: perturbation magnitude\n",
    "        \"\"\"\n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Enable gradient computation for input\n",
    "        data.requires_grad = True\n",
    "        \n",
    "        # Forward pass\n",
    "        recon_data, mu, logvar = model(data)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = vae_loss(recon_data, target, mu, logvar)\n",
    "        \n",
    "        # Zero gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Get gradient sign\n",
    "        data_grad = data.grad.data\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        \n",
    "        # Create adversarial example\n",
    "        perturbed_data = data + epsilon * sign_data_grad\n",
    "        perturbed_data = torch.clamp(perturbed_data, 0, 1)\n",
    "        \n",
    "        return perturbed_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def pgd_attack(model, data, target, epsilon, alpha, num_iter):\n",
    "        \"\"\"\n",
    "        Projected Gradient Descent (PGD) attack\n",
    "        \n",
    "        Args:\n",
    "            model: VAE model\n",
    "            data: input data\n",
    "            target: target data\n",
    "            epsilon: maximum perturbation\n",
    "            alpha: step size\n",
    "            num_iter: number of iterations\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        # Initialize perturbation\n",
    "        delta = torch.zeros_like(data).uniform_(-epsilon, epsilon)\n",
    "        delta.requires_grad = True\n",
    "        \n",
    "        for i in range(num_iter):\n",
    "            # Forward pass with perturbation\n",
    "            perturbed_data = data + delta\n",
    "            recon_data, mu, logvar = model(perturbed_data)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = vae_loss(recon_data, target, mu, logvar)\n",
    "            \n",
    "            # Calculate gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update perturbation\n",
    "            delta.data = delta.data + alpha * delta.grad.data.sign()\n",
    "            delta.data = torch.clamp(delta.data, -epsilon, epsilon)\n",
    "            delta.data = torch.clamp(data + delta.data, 0, 1) - data\n",
    "            \n",
    "            # Zero gradients\n",
    "            delta.grad.zero_()\n",
    "        \n",
    "        return data + delta\n",
    "    \n",
    "    @staticmethod\n",
    "    def latent_space_attack(model, data, epsilon, target_latent=None):\n",
    "        \"\"\"\n",
    "        Attack in latent space by perturbing encoded representations\n",
    "        \n",
    "        Args:\n",
    "            model: VAE model\n",
    "            data: input data\n",
    "            epsilon: perturbation magnitude in latent space\n",
    "            target_latent: target latent representation (optional)\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        # Encode to latent space\n",
    "        mu, logvar = model.encoder(data)\n",
    "        z = model.reparameterize(mu, logvar)\n",
    "        \n",
    "        if target_latent is not None:\n",
    "            # Move towards target latent representation\n",
    "            direction = (target_latent - z).sign()\n",
    "            perturbed_z = z + epsilon * direction\n",
    "        else:\n",
    "            # Random perturbation in latent space\n",
    "            noise = torch.randn_like(z)\n",
    "            perturbed_z = z + epsilon * noise\n",
    "        \n",
    "        # Decode back to image space\n",
    "        adversarial_recon = model.decoder(perturbed_z)\n",
    "        \n",
    "        return adversarial_recon, z, perturbed_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce955d6",
   "metadata": {},
   "source": [
    "## 6. Demonstrate Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd32faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test samples for attacks\n",
    "test_iter = iter(test_loader)\n",
    "test_data, test_labels = next(test_iter)\n",
    "test_data = test_data[:8].to(device)  # Use first 8 samples\n",
    "\n",
    "# Initialize attack methods\n",
    "attacks = AdversarialAttacks()\n",
    "\n",
    "# Show original images\n",
    "fig, axes = plt.subplots(1, 8, figsize=(16, 2))\n",
    "for i in range(8):\n",
    "    axes[i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[i].set_title(f'Original {i}')\n",
    "    axes[i].axis('off')\n",
    "plt.suptitle('Original Test Images')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a5b21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FGSM Attack - Complete Pipeline ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'attacks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== FGSM Attack - Complete Pipeline ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m epsilon_fgsm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fgsm_adversarial \u001b[38;5;241m=\u001b[39m attacks\u001b[38;5;241m.\u001b[39mfgsm_attack(model, test_data, test_data, epsilon\u001b[38;5;241m=\u001b[39mepsilon_fgsm)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Get reconstructions\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'attacks' is not defined"
     ]
    }
   ],
   "source": [
    "# FGSM Attack - Comprehensive Analysis\n",
    "print(\"\\n=== FGSM Attack - Complete Pipeline ===\")\n",
    "epsilon_fgsm = 0.1\n",
    "fgsm_adversarial = attacks.fgsm_attack(model, test_data, test_data, epsilon=epsilon_fgsm)\n",
    "\n",
    "# Get reconstructions\n",
    "with torch.no_grad():\n",
    "    original_recon, _, _ = model(test_data)\n",
    "    adversarial_recon, _, _ = model(fgsm_adversarial)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(6, 8, figsize=(16, 12))\n",
    "row_labels = [\n",
    "    'Original Input',\n",
    "    'Original Reconstruction', \n",
    "    'Adversarial Input',\n",
    "    'Adversarial Reconstruction',\n",
    "    'Input Difference (x10)',\n",
    "    'Reconstruction Difference (x10)'\n",
    "]\n",
    "\n",
    "for i in range(8):\n",
    "    # Row 1: Original inputs\n",
    "    axes[0, i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Sample {i}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Original reconstructions\n",
    "    axes[1, i].imshow(original_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Row 3: Adversarial inputs (epsilon-perturbed)\n",
    "    axes[2, i].imshow(fgsm_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[2, i].axis('off')\n",
    "    \n",
    "    # Row 4: Adversarial reconstructions\n",
    "    axes[3, i].imshow(adversarial_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[3, i].axis('off')\n",
    "    \n",
    "    # Row 5: Input differences (original vs adversarial, amplified)\n",
    "    input_diff = (fgsm_adversarial[i] - test_data[i]).detach().cpu().squeeze()\n",
    "    axes[4, i].imshow(input_diff * 10, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[4, i].axis('off')\n",
    "    \n",
    "    # Row 6: Reconstruction differences (original recon vs adversarial recon, amplified)\n",
    "    recon_diff = (adversarial_recon[i] - original_recon[i]).detach().cpu().squeeze()\n",
    "    axes[5, i].imshow(recon_diff * 10, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[5, i].axis('off')\n",
    "\n",
    "# Add row labels\n",
    "for i, label in enumerate(row_labels):\n",
    "    axes[i, 0].set_ylabel(label, rotation=90, labelpad=50, fontsize=10, ha='center')\n",
    "\n",
    "plt.suptitle(f'FGSM Attack Analysis (Œµ={epsilon_fgsm})', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display statistics\n",
    "input_perturbation = (fgsm_adversarial - test_data).detach().cpu()\n",
    "recon_perturbation = (adversarial_recon - original_recon).detach().cpu()\n",
    "\n",
    "print(f\"\\nüìä FGSM Attack Statistics:\")\n",
    "print(f\"Input Perturbation:\")\n",
    "print(f\"  L2 norm: {torch.norm(input_perturbation).item():.6f}\")\n",
    "print(f\"  L‚àû norm: {torch.max(torch.abs(input_perturbation)).item():.6f}\")\n",
    "print(f\"  Mean absolute: {torch.mean(torch.abs(input_perturbation)).item():.6f}\")\n",
    "\n",
    "print(f\"\\nReconstruction Perturbation:\")\n",
    "print(f\"  L2 norm: {torch.norm(recon_perturbation).item():.6f}\")\n",
    "print(f\"  L‚àû norm: {torch.max(torch.abs(recon_perturbation)).item():.6f}\")\n",
    "print(f\"  Mean absolute: {torch.mean(torch.abs(recon_perturbation)).item():.6f}\")\n",
    "\n",
    "print(f\"\\nAmplification Factor: {torch.norm(recon_perturbation).item() / torch.norm(input_perturbation).item():.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11dbd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD Attack - Comprehensive Analysis\n",
    "print(\"\\n=== PGD Attack - Complete Pipeline ===\")\n",
    "epsilon_pgd = 0.1\n",
    "alpha = 0.01\n",
    "num_iter = 20\n",
    "\n",
    "pgd_adversarial = attacks.pgd_attack(model, test_data, test_data, \n",
    "                                   epsilon=epsilon_pgd, alpha=alpha, num_iter=num_iter)\n",
    "\n",
    "# Get reconstructions\n",
    "with torch.no_grad():\n",
    "    original_recon, _, _ = model(test_data)\n",
    "    pgd_adversarial_recon, _, _ = model(pgd_adversarial)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(6, 8, figsize=(16, 12))\n",
    "row_labels = [\n",
    "    'Original Input',\n",
    "    'Original Reconstruction', \n",
    "    'PGD Adversarial Input',\n",
    "    'PGD Adversarial Reconstruction',\n",
    "    'Input Difference (x10)',\n",
    "    'Reconstruction Difference (x10)'\n",
    "]\n",
    "\n",
    "for i in range(8):\n",
    "    # Row 1: Original inputs\n",
    "    axes[0, i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Sample {i}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Original reconstructions\n",
    "    axes[1, i].imshow(original_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Row 3: PGD adversarial inputs\n",
    "    axes[2, i].imshow(pgd_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[2, i].axis('off')\n",
    "    \n",
    "    # Row 4: PGD adversarial reconstructions\n",
    "    axes[3, i].imshow(pgd_adversarial_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[3, i].axis('off')\n",
    "    \n",
    "    # Row 5: Input differences (original vs PGD adversarial, amplified)\n",
    "    input_diff = (pgd_adversarial[i] - test_data[i]).detach().cpu().squeeze()\n",
    "    axes[4, i].imshow(input_diff * 10, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[4, i].axis('off')\n",
    "    \n",
    "    # Row 6: Reconstruction differences (original recon vs PGD adversarial recon, amplified)\n",
    "    recon_diff = (pgd_adversarial_recon[i] - original_recon[i]).detach().cpu().squeeze()\n",
    "    axes[5, i].imshow(recon_diff * 10, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[5, i].axis('off')\n",
    "\n",
    "# Add row labels\n",
    "for i, label in enumerate(row_labels):\n",
    "    axes[i, 0].set_ylabel(label, rotation=90, labelpad=50, fontsize=10, ha='center')\n",
    "\n",
    "plt.suptitle(f'PGD Attack Analysis (Œµ={epsilon_pgd}, Œ±={alpha}, iter={num_iter})', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display statistics\n",
    "input_perturbation_pgd = (pgd_adversarial - test_data).detach().cpu()\n",
    "recon_perturbation_pgd = (pgd_adversarial_recon - original_recon).detach().cpu()\n",
    "\n",
    "print(f\"\\nüìä PGD Attack Statistics:\")\n",
    "print(f\"Input Perturbation:\")\n",
    "print(f\"  L2 norm: {torch.norm(input_perturbation_pgd).item():.6f}\")\n",
    "print(f\"  L‚àû norm: {torch.max(torch.abs(input_perturbation_pgd)).item():.6f}\")\n",
    "print(f\"  Mean absolute: {torch.mean(torch.abs(input_perturbation_pgd)).item():.6f}\")\n",
    "\n",
    "print(f\"\\nReconstruction Perturbation:\")\n",
    "print(f\"  L2 norm: {torch.norm(recon_perturbation_pgd).item():.6f}\")\n",
    "print(f\"  L‚àû norm: {torch.max(torch.abs(recon_perturbation_pgd)).item():.6f}\")\n",
    "print(f\"  Mean absolute: {torch.mean(torch.abs(recon_perturbation_pgd)).item():.6f}\")\n",
    "\n",
    "print(f\"\\nAmplification Factor: {torch.norm(recon_perturbation_pgd).item() / torch.norm(input_perturbation_pgd).item():.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ddda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare FGSM vs PGD Attack Effects\n",
    "print(\"\\n=== FGSM vs PGD Comparison ===\")\n",
    "\n",
    "# Select first 4 samples for detailed comparison\n",
    "num_samples = 4\n",
    "fig, axes = plt.subplots(7, num_samples, figsize=(12, 14))\n",
    "\n",
    "comparison_labels = [\n",
    "    'Original Input',\n",
    "    'Original Reconstruction',\n",
    "    'FGSM Adversarial',\n",
    "    'FGSM Reconstruction', \n",
    "    'PGD Adversarial',\n",
    "    'PGD Reconstruction',\n",
    "    'FGSM vs PGD Diff (x5)'\n",
    "]\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Row 1: Original inputs\n",
    "    axes[0, i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Sample {i}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Original reconstructions\n",
    "    axes[1, i].imshow(original_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Row 3: FGSM adversarial inputs\n",
    "    axes[2, i].imshow(fgsm_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[2, i].axis('off')\n",
    "    \n",
    "    # Row 4: FGSM adversarial reconstructions\n",
    "    axes[3, i].imshow(adversarial_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[3, i].axis('off')\n",
    "    \n",
    "    # Row 5: PGD adversarial inputs\n",
    "    axes[4, i].imshow(pgd_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[4, i].axis('off')\n",
    "    \n",
    "    # Row 6: PGD adversarial reconstructions\n",
    "    axes[5, i].imshow(pgd_adversarial_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[5, i].axis('off')\n",
    "    \n",
    "    # Row 7: Difference between FGSM and PGD adversarial inputs\n",
    "    fgsm_vs_pgd_diff = (fgsm_adversarial[i] - pgd_adversarial[i]).detach().cpu().squeeze()\n",
    "    axes[6, i].imshow(fgsm_vs_pgd_diff * 5, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[6, i].axis('off')\n",
    "\n",
    "# Add row labels\n",
    "for i, label in enumerate(comparison_labels):\n",
    "    axes[i, 0].set_ylabel(label, rotation=90, labelpad=40, fontsize=9, ha='center')\n",
    "\n",
    "plt.suptitle('FGSM vs PGD Attack Comparison', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.18)\n",
    "plt.show()\n",
    "\n",
    "# Quantitative comparison\n",
    "print(f\"\\nüìà Attack Method Comparison:\")\n",
    "print(f\"{'Metric':<25} {'FGSM':<12} {'PGD':<12} {'Ratio (PGD/FGSM)':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "fgsm_input_l2 = torch.norm(input_perturbation).item()\n",
    "pgd_input_l2 = torch.norm(input_perturbation_pgd).item()\n",
    "print(f\"{'Input L2 Perturbation':<25} {fgsm_input_l2:<12.6f} {pgd_input_l2:<12.6f} {pgd_input_l2/fgsm_input_l2:<15.2f}\")\n",
    "\n",
    "fgsm_recon_l2 = torch.norm(recon_perturbation).item()\n",
    "pgd_recon_l2 = torch.norm(recon_perturbation_pgd).item()\n",
    "print(f\"{'Recon L2 Perturbation':<25} {fgsm_recon_l2:<12.6f} {pgd_recon_l2:<12.6f} {pgd_recon_l2/fgsm_recon_l2:<15.2f}\")\n",
    "\n",
    "fgsm_input_linf = torch.max(torch.abs(input_perturbation)).item()\n",
    "pgd_input_linf = torch.max(torch.abs(input_perturbation_pgd)).item()\n",
    "print(f\"{'Input L‚àû Perturbation':<25} {fgsm_input_linf:<12.6f} {pgd_input_linf:<12.6f} {pgd_input_linf/fgsm_input_linf:<15.2f}\")\n",
    "\n",
    "fgsm_recon_linf = torch.max(torch.abs(recon_perturbation)).item()\n",
    "pgd_recon_linf = torch.max(torch.abs(recon_perturbation_pgd)).item()\n",
    "print(f\"{'Recon L‚àû Perturbation':<25} {fgsm_recon_linf:<12.6f} {pgd_recon_linf:<12.6f} {pgd_recon_linf/fgsm_recon_linf:<15.2f}\")\n",
    "\n",
    "# Check if attacks are different\n",
    "attack_similarity = F.mse_loss(fgsm_adversarial, pgd_adversarial).item()\n",
    "print(f\"\\nüîç Attack Similarity (MSE between FGSM and PGD adversarial inputs): {attack_similarity:.6f}\")\n",
    "if attack_similarity < 1e-6:\n",
    "    print(\"‚ö†Ô∏è  Warning: FGSM and PGD attacks produced nearly identical results!\")\n",
    "else:\n",
    "    print(\"‚úì FGSM and PGD attacks produced different adversarial examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357dff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Space Attack\n",
    "print(\"\\n=== Latent Space Attack ===\")\n",
    "epsilon_latent = 2.0\n",
    "\n",
    "latent_adversarial, orig_latent, perturbed_latent = attacks.latent_space_attack(\n",
    "    model, test_data, epsilon=epsilon_latent)\n",
    "\n",
    "# Get original reconstructions for comparison\n",
    "with torch.no_grad():\n",
    "    original_recon, _, _ = model(test_data)\n",
    "\n",
    "# Visualize latent space attack results\n",
    "fig, axes = plt.subplots(3, 8, figsize=(16, 6))\n",
    "for i in range(8):\n",
    "    # Original\n",
    "    axes[0, i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Original {i}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Original reconstruction\n",
    "    axes[1, i].imshow(original_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[1, i].set_title(f'Original Recon')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Latent attack result\n",
    "    axes[2, i].imshow(latent_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[2, i].set_title(f'Latent Attack')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.suptitle(f'Latent Space Attack Results (Œµ={epsilon_latent})')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show latent space perturbations\n",
    "print(f\"Latent space perturbation magnitude: {torch.norm(perturbed_latent - orig_latent).item():.6f}\")\n",
    "print(f\"Original latent mean: {orig_latent.mean(dim=0).detach().cpu().numpy()}\")\n",
    "print(f\"Perturbed latent mean: {perturbed_latent.mean(dim=0).detach().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e08762",
   "metadata": {},
   "source": [
    "## 7. Evaluate Attack Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack_effectiveness(model, original, adversarial, attack_name):\n",
    "    \"\"\"Evaluate the effectiveness of adversarial attacks\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Reconstruct original\n",
    "        recon_orig, mu_orig, logvar_orig = model(original)\n",
    "        \n",
    "        # Reconstruct adversarial\n",
    "        recon_adv, mu_adv, logvar_adv = model(adversarial)\n",
    "        \n",
    "        # Calculate reconstruction errors\n",
    "        orig_error = F.mse_loss(recon_orig, original).item()\n",
    "        adv_error = F.mse_loss(recon_adv, adversarial).item()\n",
    "        \n",
    "        # Calculate latent space distances\n",
    "        latent_distance = F.mse_loss(mu_orig, mu_adv).item()\n",
    "        \n",
    "        # Calculate input perturbation\n",
    "        input_perturbation = F.mse_loss(original, adversarial).item()\n",
    "        \n",
    "        print(f\"\\n=== {attack_name} Effectiveness ===\")\n",
    "        print(f\"Original Reconstruction Error: {orig_error:.6f}\")\n",
    "        print(f\"Adversarial Reconstruction Error: {adv_error:.6f}\")\n",
    "        print(f\"Latent Space Distance: {latent_distance:.6f}\")\n",
    "        print(f\"Input Perturbation (MSE): {input_perturbation:.6f}\")\n",
    "        \n",
    "        return orig_error, adv_error, latent_distance, input_perturbation\n",
    "\n",
    "# Evaluate all attacks\n",
    "fgsm_results = evaluate_attack_effectiveness(model, test_data, fgsm_adversarial, \"FGSM\")\n",
    "pgd_results = evaluate_attack_effectiveness(model, test_data, pgd_adversarial, \"PGD\")\n",
    "\n",
    "# For latent attack, compare original reconstruction vs latent attack result\n",
    "with torch.no_grad():\n",
    "    orig_recon, orig_mu, orig_logvar = model(test_data)\n",
    "    latent_mse = F.mse_loss(orig_recon, latent_adversarial).item()\n",
    "    print(f\"\\n=== Latent Space Attack Effectiveness ===\")\n",
    "    print(f\"Original vs Latent Attack Reconstruction MSE: {latent_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c622df4",
   "metadata": {},
   "source": [
    "## 8. Robustness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test robustness across different epsilon values\n",
    "print(\"\\n=== Robustness Analysis ===\")\n",
    "epsilons = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "fgsm_errors = []\n",
    "pgd_errors = []\n",
    "perturbation_magnitudes = []\n",
    "\n",
    "for eps in tqdm(epsilons, desc=\"Testing epsilon values\"):\n",
    "    # FGSM\n",
    "    fgsm_adv = attacks.fgsm_attack(model, test_data, test_data, epsilon=eps)\n",
    "    _, fgsm_error, _, fgsm_pert = evaluate_attack_effectiveness(model, test_data, fgsm_adv, f\"FGSM-{eps}\")\n",
    "    fgsm_errors.append(fgsm_error)\n",
    "    \n",
    "    # PGD\n",
    "    pgd_adv = attacks.pgd_attack(model, test_data, test_data, epsilon=eps, alpha=0.01, num_iter=10)\n",
    "    _, pgd_error, _, pgd_pert = evaluate_attack_effectiveness(model, test_data, pgd_adv, f\"PGD-{eps}\")\n",
    "    pgd_errors.append(pgd_error)\n",
    "    \n",
    "    perturbation_magnitudes.append(eps)\n",
    "\n",
    "# Plot robustness curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epsilons, fgsm_errors, 'o-', label='FGSM', linewidth=2)\n",
    "plt.plot(epsilons, pgd_errors, 's-', label='PGD', linewidth=2)\n",
    "plt.xlabel('Epsilon (Perturbation Magnitude)')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('VAE Robustness vs Perturbation Magnitude')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Test different latent space perturbation magnitudes\n",
    "latent_epsilons = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "latent_errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    orig_recon, _, _ = model(test_data)\n",
    "\n",
    "for eps in latent_epsilons:\n",
    "    latent_adv, _, _ = attacks.latent_space_attack(model, test_data, epsilon=eps)\n",
    "    error = F.mse_loss(orig_recon, latent_adv).item()\n",
    "    latent_errors.append(error)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(latent_epsilons, latent_errors, '^-', color='green', linewidth=2)\n",
    "plt.xlabel('Latent Space Perturbation Magnitude')\n",
    "plt.ylabel('Reconstruction Difference (MSE)')\n",
    "plt.title('Latent Space Attack Effectiveness')\n",
    "plt.grid(True)\n",
    "\n",
    "# Compare attack methods\n",
    "plt.subplot(1, 3, 3)\n",
    "methods = ['Original', 'FGSM\\n(Œµ=0.1)', 'PGD\\n(Œµ=0.1)', 'Latent\\n(Œµ=2.0)']\n",
    "errors = [fgsm_results[0], fgsm_results[1], pgd_results[1], latent_mse]\n",
    "colors = ['blue', 'red', 'orange', 'green']\n",
    "\n",
    "bars = plt.bar(methods, errors, color=colors, alpha=0.7)\n",
    "plt.ylabel('Reconstruction Error / MSE')\n",
    "plt.title('Attack Method Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, error in zip(bars, errors):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.0001, \n",
    "             f'{error:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8d0715",
   "metadata": {},
   "source": [
    "## 9. Visualize Latent Space Perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e71041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how attacks affect the latent space\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get latent representations\n",
    "    mu_orig, _ = model.encoder(test_data[:4])\n",
    "    mu_fgsm, _ = model.encoder(fgsm_adversarial[:4])\n",
    "    mu_pgd, _ = model.encoder(pgd_adversarial[:4])\n",
    "\n",
    "# Plot latent space movements\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "for i in range(4):\n",
    "    # Original point\n",
    "    plt.scatter(mu_orig[i, 0].cpu(), mu_orig[i, 1].cpu(), \n",
    "               color=colors[i], s=100, marker='o', label=f'Original {i}' if i < 4 else \"\")\n",
    "    \n",
    "    # FGSM point\n",
    "    plt.scatter(mu_fgsm[i, 0].cpu(), mu_fgsm[i, 1].cpu(), \n",
    "               color=colors[i], s=100, marker='x', alpha=0.7)\n",
    "    \n",
    "    # PGD point\n",
    "    plt.scatter(mu_pgd[i, 0].cpu(), mu_pgd[i, 1].cpu(), \n",
    "               color=colors[i], s=100, marker='^', alpha=0.7)\n",
    "    \n",
    "    # Draw arrows showing movement\n",
    "    plt.arrow(mu_orig[i, 0].cpu(), mu_orig[i, 1].cpu(),\n",
    "             mu_fgsm[i, 0].cpu() - mu_orig[i, 0].cpu(),\n",
    "             mu_fgsm[i, 1].cpu() - mu_orig[i, 1].cpu(),\n",
    "             color=colors[i], alpha=0.5, head_width=0.1, linestyle='--')\n",
    "    \n",
    "    plt.arrow(mu_orig[i, 0].cpu(), mu_orig[i, 1].cpu(),\n",
    "             mu_pgd[i, 0].cpu() - mu_orig[i, 0].cpu(),\n",
    "             mu_pgd[i, 1].cpu() - mu_orig[i, 1].cpu(),\n",
    "             color=colors[i], alpha=0.5, head_width=0.1, linestyle='-')\n",
    "\n",
    "# Create custom legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='black', markersize=8, label='Original'),\n",
    "    Line2D([0], [0], marker='x', color='w', markerfacecolor='black', markersize=8, label='FGSM'),\n",
    "    Line2D([0], [0], marker='^', color='w', markerfacecolor='black', markersize=8, label='PGD'),\n",
    "    Line2D([0], [0], color='black', linestyle='--', label='FGSM Movement'),\n",
    "    Line2D([0], [0], color='black', linestyle='-', label='PGD Movement')\n",
    "]\n",
    "\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.title('Latent Space Perturbations from Adversarial Attacks')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814084bb",
   "metadata": {},
   "source": [
    "## 10. Defense Mechanisms (Bonus)\n",
    "\n",
    "Here are some strategies to improve VAE robustness against adversarial attacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd7e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_training_step(model, data, optimizer, epsilon=0.1, alpha=0.01):\n",
    "    \"\"\"\n",
    "    Single step of adversarial training\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # Generate adversarial examples\n",
    "    model.eval()\n",
    "    adv_data = AdversarialAttacks.fgsm_attack(model, data, data, epsilon)\n",
    "    model.train()\n",
    "    \n",
    "    # Train on both clean and adversarial data\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Clean loss\n",
    "    recon_clean, mu_clean, logvar_clean = model(data)\n",
    "    clean_loss = vae_loss(recon_clean, data, mu_clean, logvar_clean)\n",
    "    \n",
    "    # Adversarial loss\n",
    "    recon_adv, mu_adv, logvar_adv = model(adv_data)\n",
    "    adv_loss = vae_loss(recon_adv, adv_data, mu_adv, logvar_adv)\n",
    "    \n",
    "    # Combined loss\n",
    "    total_loss = 0.5 * clean_loss + 0.5 * adv_loss\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return total_loss.item()\n",
    "\n",
    "print(\"Defense Strategies for VAEs:\")\n",
    "print(\"1. Adversarial Training: Train on both clean and adversarial examples\")\n",
    "print(\"2. Input Preprocessing: Add noise or apply transformations\")\n",
    "print(\"3. Regularization: Increase Œ≤ in Œ≤-VAE to enforce stronger regularization\")\n",
    "print(\"4. Ensemble Methods: Use multiple VAE models and average predictions\")\n",
    "print(\"5. Certified Defenses: Use techniques like randomized smoothing\")\n",
    "\n",
    "# Example: Train a model with higher Œ≤ for better regularization\n",
    "robust_model = VAE(latent_dim=2)\n",
    "print(\"\\nTraining a more robust VAE with Œ≤=5.0...\")\n",
    "robust_losses = train_vae(robust_model, train_loader, epochs=5, beta=5.0)\n",
    "\n",
    "# Test robustness of the new model\n",
    "print(\"\\nTesting robustness of Œ≤-VAE:\")\n",
    "robust_fgsm = attacks.fgsm_attack(robust_model, test_data, test_data, epsilon=0.1)\n",
    "evaluate_attack_effectiveness(robust_model, test_data, robust_fgsm, \"Robust Œ≤-VAE FGSM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dbe769",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated several key concepts in adversarial attacks on VAEs:\n",
    "\n",
    "### Attack Methods:\n",
    "1. **FGSM (Fast Gradient Sign Method)**: Single-step attack using gradient sign\n",
    "2. **PGD (Projected Gradient Descent)**: Multi-step iterative attack\n",
    "3. **Latent Space Attack**: Perturbations in the encoded latent representation\n",
    "\n",
    "### Key Findings:\n",
    "- VAEs are vulnerable to adversarial perturbations in both input and latent spaces\n",
    "- Small input perturbations can cause significant changes in latent representations\n",
    "- The 2D latent space makes visualization of attack effects possible\n",
    "- Different attack methods have varying effectiveness\n",
    "\n",
    "### Defense Strategies:\n",
    "- Adversarial training with mixed clean/adversarial data\n",
    "- Stronger regularization (higher Œ≤ in Œ≤-VAE)\n",
    "- Input preprocessing and ensemble methods\n",
    "- Certified defense techniques\n",
    "\n",
    "This framework can be extended to other autoencoder architectures and datasets to study adversarial robustness in generative models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
