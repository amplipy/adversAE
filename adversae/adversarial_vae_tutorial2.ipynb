{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a67261a",
   "metadata": {},
   "source": [
    "# Adversarial Attacks on Variational Autoencoders\n",
    "\n",
    "This notebook demonstrates how to engineer adversarial attacks against a VAE using MNIST dataset with LeNet-style encoder/decoder and 2D latent space.\n",
    "\n",
    "## Key Concepts:\n",
    "- **FGSM (Fast Gradient Sign Method)**: Single-step attack using gradient sign\n",
    "- **PGD (Projected Gradient Descent)**: Multi-step iterative attack\n",
    "- **Latent Space Attack**: Attack in the encoded latent representation\n",
    "- **VAE Vulnerabilities**: How reconstruction and regularization losses affect robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d676d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision numpy matplotlib tqdm psutil\n",
    "\n",
    "# Install GPU monitoring tools (optional - will fallback to nvidia-smi if not available)\n",
    "try:\n",
    "    !pip install nvidia-ml-py\n",
    "    print(\"‚úì nvidia-ml-py installed for efficient GPU monitoring\")\n",
    "except:\n",
    "    print(\"‚ö† nvidia-ml-py not available, will use nvidia-smi fallback\")\n",
    "\n",
    "# Check if nvidia-smi is available\n",
    "import subprocess\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi', '--version'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úì nvidia-smi available for GPU monitoring\")\n",
    "    else:\n",
    "        print(\"‚ö† nvidia-smi not available - GPU monitoring will show zeros\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö† nvidia-smi not found - GPU monitoring will show zeros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25cd069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e1ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check if GPU is available and print basic info\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"No GPU available - using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20929af",
   "metadata": {},
   "source": [
    "## 1. Define VAE Architecture with LeNet-style Encoder/Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetEncoder(nn.Module):\n",
    "    \"\"\"LeNet-style encoder for VAE\"\"\"\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super(LeNetEncoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Convolutional layers (LeNet-style)\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)  # 28x28 -> 28x28\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # 28x28 -> 14x14\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)  # 14x14 -> 10x10\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # 10x10 -> 5x5\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        \n",
    "        # Output layers for mean and log variance\n",
    "        self.fc_mu = nn.Linear(84, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(84, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Output mean and log variance\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5158fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetDecoder(nn.Module):\n",
    "    \"\"\"LeNet-style decoder for VAE\"\"\"\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super(LeNetDecoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(latent_dim, 84)\n",
    "        self.fc2 = nn.Linear(84, 120)\n",
    "        self.fc3 = nn.Linear(120, 16 * 5 * 5)\n",
    "        \n",
    "        # Transposed convolutional layers (reverse of encoder)\n",
    "        self.deconv1 = nn.ConvTranspose2d(16, 6, kernel_size=5, stride=2, padding=2, output_padding=1)  # 5x5 -> 10x10\n",
    "        self.deconv2 = nn.ConvTranspose2d(6, 1, kernel_size=5, stride=2, padding=2, output_padding=1)   # 10x10 -> 20x20\n",
    "        # Add padding to get from 20x20 to 28x28\n",
    "        self.final_conv = nn.ConvTranspose2d(1, 1, kernel_size=9, stride=1, padding=0)  # 20x20 -> 28x28\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(z))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        # Reshape to feature maps\n",
    "        x = x.view(-1, 16, 5, 5)\n",
    "        \n",
    "        # Transposed convolutional layers\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = torch.sigmoid(self.final_conv(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7341240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"Variational Autoencoder with LeNet-style architecture\"\"\"\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = LeNetEncoder(latent_dim)\n",
    "        self.decoder = LeNetDecoder(latent_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Reparameterization trick\"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decoder(z)\n",
    "        return recon_x, mu, logvar\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input to latent space\"\"\"\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return self.reparameterize(mu, logvar)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode from latent space\"\"\"\n",
    "        return self.decoder(z)\n",
    "\n",
    "def vae_loss(recon_x, x, mu, logvar, beta=1.0):\n",
    "    \"\"\"\n",
    "    FIXED VAE loss function with proper scaling\n",
    "    \n",
    "    The original had major scaling issues:\n",
    "    - reconstruction loss was summed over batch AND pixels\n",
    "    - KL loss was summed over batch AND latent dims\n",
    "    - This made losses scale with batch size, causing instability\n",
    "    \"\"\"\n",
    "    batch_size = x.size(0)\n",
    "    \n",
    "    # Reconstruction loss - properly normalized\n",
    "    # BCE should be averaged over batch and pixels, not summed\n",
    "    recon_loss = F.binary_cross_entropy(recon_x, x, reduction='mean')\n",
    "    \n",
    "    # KL divergence loss - properly normalized\n",
    "    # KL should be averaged over batch, summed over latent dims\n",
    "    kl_loss = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
    "    \n",
    "    return recon_loss + beta * kl_loss\n",
    "\n",
    "# üö® CRITICAL ISSUE EXPLANATION:\n",
    "print(\"üö® MAJOR VAE LOSS SCALING ISSUE IDENTIFIED!\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚ùå ORIGINAL PROBLEM:\")\n",
    "print(\"   ‚Ä¢ Reconstruction loss: reduction='sum' ‚Üí scales with batch_size * pixels\")\n",
    "print(\"   ‚Ä¢ KL loss: torch.sum(...) ‚Üí scales with batch_size * latent_dims\")\n",
    "print(\"   ‚Ä¢ With batch_size=2048: losses become HUGE!\")\n",
    "print(\"   ‚Ä¢ Model learns to minimize by making reconstructions blurry/constant\")\n",
    "print(\"\")\n",
    "print(\"‚úÖ FIXED VERSION:\")\n",
    "print(\"   ‚Ä¢ Reconstruction loss: reduction='mean' ‚Üí normalized per sample\")\n",
    "print(\"   ‚Ä¢ KL loss: torch.mean(torch.sum(..., dim=1)) ‚Üí proper normalization\") \n",
    "print(\"   ‚Ä¢ Losses stay stable regardless of batch size\")\n",
    "print(\"   ‚Ä¢ Model can learn proper reconstructions\")\n",
    "print(\"\")\n",
    "print(\"üìä IMPACT DEMONSTRATION:\")\n",
    "\n",
    "# Show the scaling difference\n",
    "dummy_batch_size = [128, 512, 1024, 2048]\n",
    "dummy_recon = torch.ones(1, 1, 28, 28)  # Perfect reconstruction\n",
    "dummy_x = torch.ones(1, 1, 28, 28)\n",
    "dummy_mu = torch.zeros(1, 2)\n",
    "dummy_logvar = torch.zeros(1, 2)\n",
    "\n",
    "print(f\"{'Batch Size':<12} {'Old Loss':<15} {'New Loss':<15} {'Ratio':<10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for bs in dummy_batch_size:\n",
    "    # Simulate larger batch\n",
    "    recon_batch = dummy_recon.repeat(bs, 1, 1, 1)\n",
    "    x_batch = dummy_x.repeat(bs, 1, 1, 1)\n",
    "    mu_batch = dummy_mu.repeat(bs, 1)\n",
    "    logvar_batch = dummy_logvar.repeat(bs, 1)\n",
    "    \n",
    "    # Old loss (broken)\n",
    "    old_recon = F.binary_cross_entropy(recon_batch, x_batch, reduction='sum')\n",
    "    old_kl = -0.5 * torch.sum(1 + logvar_batch - mu_batch.pow(2) - logvar_batch.exp())\n",
    "    old_total = old_recon + old_kl\n",
    "    \n",
    "    # New loss (fixed) \n",
    "    new_recon = F.binary_cross_entropy(recon_batch, x_batch, reduction='mean')\n",
    "    new_kl = -0.5 * torch.mean(torch.sum(1 + logvar_batch - mu_batch.pow(2) - logvar_batch.exp(), dim=1))\n",
    "    new_total = new_recon + new_kl\n",
    "    \n",
    "    ratio = old_total / new_total\n",
    "    print(f\"{bs:<12} {old_total.item():<15.3f} {new_total.item():<15.3f} {ratio.item():<10.1f}x\")\n",
    "\n",
    "print(\"\\nüí° This explains why your reconstructions were horrible!\")\n",
    "print(\"   The old loss scaled quadratically with batch size, making training unstable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667618d6",
   "metadata": {},
   "source": [
    "## 2. Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980fbb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset with optimizations for A100\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "# Increase batch size significantly for A100 - can handle much larger batches\n",
    "# A100 has 40-80GB memory, so we can use much larger batches\n",
    "batch_size_train = 2048  # Much larger for A100\n",
    "batch_size_test = 1024\n",
    "\n",
    "# Add num_workers for faster data loading and pin_memory for GPU transfer\n",
    "num_workers = 4  # Adjust based on your CPU cores\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size_train, \n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,  # Faster GPU transfer\n",
    "    persistent_workers=True  # Keep workers alive between epochs\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size_test, \n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Training batch size: {batch_size_train} (optimized for A100)\")\n",
    "print(f\"Test batch size: {batch_size_test}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")\n",
    "\n",
    "# Visualize some samples\n",
    "def show_samples(loader, num_samples=8):\n",
    "    data_iter = iter(loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(12, 2))\n",
    "    for i in range(num_samples):\n",
    "        axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Label: {labels[i]}')\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90f158",
   "metadata": {},
   "source": [
    "## 3. Train the VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, train_loader, epochs=10, lr=1e-3, beta=1.0, use_amp=True):\n",
    "    \"\"\"\n",
    "    Train the VAE model with A100 optimizations\n",
    "    \n",
    "    Args:\n",
    "        use_amp: Use Automatic Mixed Precision for A100 efficiency\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Initialize mixed precision training for A100\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp and torch.cuda.is_available() else None\n",
    "    \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    # Compile model for A100 (PyTorch 2.0+)\n",
    "    try:\n",
    "        model = torch.compile(model)\n",
    "        print(\"‚úÖ Model compiled for A100 optimization\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è  Model compilation not available (PyTorch < 2.0)\")\n",
    "    \n",
    "    print(f\"Training VAE with {'mixed precision' if use_amp else 'full precision'}...\")\n",
    "    print(f\"Batch size: {train_loader.batch_size} (A100 optimized)\")\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        epoch_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.to(device, non_blocking=True)  # Async GPU transfer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if use_amp and scaler is not None:\n",
    "                # Mixed precision forward pass\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    recon_batch, mu, logvar = model(data)\n",
    "                    loss = vae_loss(recon_batch, data, mu, logvar, beta)\n",
    "                \n",
    "                # Mixed precision backward pass\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # Standard precision training\n",
    "                recon_batch, mu, logvar = model(data)\n",
    "                loss = vae_loss(recon_batch, data, mu, logvar, beta)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            batch_count += 1\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_loader.dataset)\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}, Batches: {batch_count}')\n",
    "    \n",
    "    return train_losses\n",
    "\n",
    "# Initialize model with larger capacity for A100\n",
    "# We can afford a bigger model on A100\n",
    "model = VAE(latent_dim=2)\n",
    "\n",
    "# Check model size\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"üìä Model Statistics:\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: ~{total_params * 4 / 1e6:.2f} MB (float32)\")\n",
    "\n",
    "# Check GPU memory before training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"A100 Total Memory: {total_memory:.1f} GB\")\n",
    "    print(f\"Current usage: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2a99ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç VAE Training Diagnostics - Let's identify the reconstruction problem\n",
    "\n",
    "def diagnose_vae_issues(model, train_loader, test_loader):\n",
    "    \"\"\"Comprehensive VAE diagnostics to identify training issues\"\"\"\n",
    "    \n",
    "    print(\"üîç Running VAE Diagnostics...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Check model architecture\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    encoder_params = sum(p.numel() for p in model.encoder.parameters())\n",
    "    decoder_params = sum(p.numel() for p in model.decoder.parameters())\n",
    "    \n",
    "    print(f\"üìä Model Architecture:\")\n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Encoder parameters: {encoder_params:,}\")\n",
    "    print(f\"  Decoder parameters: {decoder_params:,}\")\n",
    "    print(f\"  Latent dimensions: {model.latent_dim}\")\n",
    "    \n",
    "    # 2. Test forward pass\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_batch = next(iter(test_loader))[0][:8].to(device)\n",
    "        \n",
    "        # Check input range\n",
    "        print(f\"\\nüìà Data Diagnostics:\")\n",
    "        print(f\"  Input shape: {test_batch.shape}\")\n",
    "        print(f\"  Input range: [{test_batch.min():.4f}, {test_batch.max():.4f}]\")\n",
    "        print(f\"  Input mean: {test_batch.mean():.4f}\")\n",
    "        print(f\"  Input std: {test_batch.std():.4f}\")\n",
    "        \n",
    "        # Forward pass\n",
    "        recon, mu, logvar = model(test_batch)\n",
    "        \n",
    "        # Check outputs\n",
    "        print(f\"\\nüß† Model Outputs:\")\n",
    "        print(f\"  Reconstruction shape: {recon.shape}\")\n",
    "        print(f\"  Reconstruction range: [{recon.min():.4f}, {recon.max():.4f}]\")\n",
    "        print(f\"  Reconstruction mean: {recon.mean():.4f}\")\n",
    "        print(f\"  Latent mu range: [{mu.min():.4f}, {mu.max():.4f}]\")\n",
    "        print(f\"  Latent mu mean: {mu.mean():.4f}\")\n",
    "        print(f\"  Latent logvar range: [{logvar.min():.4f}, {logvar.max():.4f}]\")\n",
    "        print(f\"  Latent logvar mean: {logvar.mean():.4f}\")\n",
    "        \n",
    "        # Check for common issues\n",
    "        issues_found = []\n",
    "        \n",
    "        # Issue 1: Reconstruction saturation\n",
    "        if recon.min() < 0.01 or recon.max() > 0.99:\n",
    "            issues_found.append(\"‚ùå Reconstruction saturation (values near 0 or 1)\")\n",
    "        \n",
    "        # Issue 2: Latent collapse\n",
    "        if mu.std() < 0.1:\n",
    "            issues_found.append(\"‚ùå Potential latent collapse (mu std too low)\")\n",
    "        \n",
    "        # Issue 3: KL divergence issues\n",
    "        if logvar.mean() < -10:\n",
    "            issues_found.append(\"‚ùå KL collapse (logvar too negative)\")\n",
    "        elif logvar.mean() > 5:\n",
    "            issues_found.append(\"‚ùå KL explosion (logvar too positive)\")\n",
    "        \n",
    "        # Issue 4: Reconstruction loss\n",
    "        recon_loss = F.binary_cross_entropy(recon, test_batch, reduction='mean')\n",
    "        if recon_loss > 0.5:\n",
    "            issues_found.append(f\"‚ùå High reconstruction loss ({recon_loss:.4f})\")\n",
    "        \n",
    "        # Issue 5: Dead neurons\n",
    "        relu_activations = []\n",
    "        def hook_fn(module, input, output):\n",
    "            if isinstance(module, nn.ReLU):\n",
    "                relu_activations.append((output == 0).float().mean().item())\n",
    "        \n",
    "        hooks = []\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, nn.ReLU):\n",
    "                hooks.append(module.register_forward_hook(hook_fn))\n",
    "        \n",
    "        _ = model(test_batch)\n",
    "        \n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "        \n",
    "        if relu_activations and max(relu_activations) > 0.9:\n",
    "            issues_found.append(\"‚ùå Dead ReLU neurons detected\")\n",
    "        \n",
    "        print(f\"\\nüö® Issues Detected:\")\n",
    "        if issues_found:\n",
    "            for issue in issues_found:\n",
    "                print(f\"  {issue}\")\n",
    "        else:\n",
    "            print(\"  ‚úÖ No obvious issues detected\")\n",
    "        \n",
    "        # 3. Visual inspection\n",
    "        print(f\"\\nüñºÔ∏è  Visual Diagnostics:\")\n",
    "        fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "        \n",
    "        for i in range(8):\n",
    "            # Original\n",
    "            axes[0, i].imshow(test_batch[i].cpu().squeeze(), cmap='gray')\n",
    "            axes[0, i].set_title(f'Original {i}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Reconstruction\n",
    "            axes[1, i].imshow(recon[i].cpu().squeeze(), cmap='gray')\n",
    "            axes[1, i].set_title(f'Recon {i}')\n",
    "            axes[1, i].axis('off')\n",
    "        \n",
    "        plt.suptitle('Original vs Reconstruction Comparison')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate reconstruction quality\n",
    "        mse_loss = F.mse_loss(recon, test_batch, reduction='mean')\n",
    "        print(f\"  MSE Loss: {mse_loss:.6f}\")\n",
    "        print(f\"  BCE Loss: {recon_loss:.6f}\")\n",
    "        \n",
    "        return issues_found, recon_loss.item(), mse_loss.item()\n",
    "\n",
    "# Run diagnostics\n",
    "print(\"üîß Diagnosing VAE training issues...\")\n",
    "issues, bce_loss, mse_loss = diagnose_vae_issues(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77966dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ†Ô∏è Fixed VAE Implementation - Addressing Common Issues\n",
    "\n",
    "def improved_vae_loss(recon_x, x, mu, logvar, beta=1.0, recon_loss_type='mse'):\n",
    "    \"\"\"\n",
    "    Improved VAE loss function with better numerical stability\n",
    "    \n",
    "    Args:\n",
    "        recon_loss_type: 'mse' or 'bce' - MSE often works better than BCE\n",
    "    \"\"\"\n",
    "    # Reconstruction loss - try MSE instead of BCE\n",
    "    if recon_loss_type == 'mse':\n",
    "        recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    else:\n",
    "        # Add epsilon for numerical stability in BCE\n",
    "        epsilon = 1e-8\n",
    "        recon_x_stable = torch.clamp(recon_x, epsilon, 1 - epsilon)\n",
    "        recon_loss = F.binary_cross_entropy(recon_x_stable, x, reduction='sum')\n",
    "    \n",
    "    # KL divergence loss with numerical stability\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return recon_loss + beta * kl_loss, recon_loss, kl_loss\n",
    "\n",
    "def train_vae_improved(model, train_loader, epochs=10, lr=1e-3, beta=1.0, \n",
    "                       use_amp=False, recon_loss_type='mse', warmup_epochs=5):\n",
    "    \"\"\"\n",
    "    Improved VAE training with better practices\n",
    "    \n",
    "    Args:\n",
    "        use_amp: Disabled by default as it can cause issues with VAE training\n",
    "        recon_loss_type: 'mse' often works better than 'bce' for MNIST\n",
    "        warmup_epochs: Gradually increase beta for KL annealing\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "    \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    recon_losses = []\n",
    "    kl_losses = []\n",
    "    \n",
    "    print(f\"Training improved VAE...\")\n",
    "    print(f\"Reconstruction loss: {recon_loss_type}\")\n",
    "    print(f\"KL warmup epochs: {warmup_epochs}\")\n",
    "    print(f\"Mixed precision: {'Enabled' if use_amp else 'Disabled (recommended for VAE)'}\")\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        epoch_loss = 0\n",
    "        epoch_recon_loss = 0\n",
    "        epoch_kl_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        # KL annealing - gradually increase beta\n",
    "        if epoch < warmup_epochs:\n",
    "            current_beta = beta * (epoch / warmup_epochs)\n",
    "        else:\n",
    "            current_beta = beta\n",
    "        \n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    recon_batch, mu, logvar = model(data)\n",
    "                    loss, recon_loss, kl_loss = improved_vae_loss(\n",
    "                        recon_batch, data, mu, logvar, current_beta, recon_loss_type)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # Standard precision (recommended for VAE)\n",
    "                recon_batch, mu, logvar = model(data)\n",
    "                loss, recon_loss, kl_loss = improved_vae_loss(\n",
    "                    recon_batch, data, mu, logvar, current_beta, recon_loss_type)\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                # Gradient clipping to prevent exploding gradients\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_recon_loss += recon_loss.item()\n",
    "            epoch_kl_loss += kl_loss.item()\n",
    "            batch_count += 1\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_loader.dataset)\n",
    "        avg_recon_loss = epoch_recon_loss / len(train_loader.dataset)\n",
    "        avg_kl_loss = epoch_kl_loss / len(train_loader.dataset)\n",
    "        \n",
    "        train_losses.append(avg_loss)\n",
    "        recon_losses.append(avg_recon_loss)\n",
    "        kl_losses.append(avg_kl_loss)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(avg_loss)\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == epochs - 1:\n",
    "            print(f'Epoch {epoch:3d}, Total Loss: {avg_loss:.4f}, '\n",
    "                  f'Recon: {avg_recon_loss:.4f}, KL: {avg_kl_loss:.4f}, '\n",
    "                  f'Beta: {current_beta:.3f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "    \n",
    "    return train_losses, recon_losses, kl_losses\n",
    "\n",
    "# Create a fresh model instance\n",
    "print(\"üîÑ Creating fresh VAE model...\")\n",
    "model_improved = VAE(latent_dim=2)\n",
    "\n",
    "# Check the model\n",
    "total_params = sum(p.numel() for p in model_improved.parameters())\n",
    "print(f\"Model parameters: {total_params:,}\")\n",
    "\n",
    "# Run quick diagnostic on untrained model\n",
    "print(f\"\\nüìã Testing untrained model...\")\n",
    "with torch.no_grad():\n",
    "    test_batch = next(iter(test_loader))[0][:4].to(device)\n",
    "    recon, mu, logvar = model_improved(test_batch)\n",
    "    print(f\"Untrained reconstruction range: [{recon.min():.4f}, {recon.max():.4f}]\")\n",
    "    print(f\"Untrained latent mu range: [{mu.min():.4f}, {mu.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e7824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Train VAE with Improved Settings\n",
    "\n",
    "print(\"üîß Training VAE with improved settings...\")\n",
    "print(\"Key improvements:\")\n",
    "print(\"‚Ä¢ Using MSE loss instead of BCE (often better for MNIST)\")\n",
    "print(\"‚Ä¢ KL annealing (gradual beta increase)\")\n",
    "print(\"‚Ä¢ Gradient clipping\")\n",
    "print(\"‚Ä¢ Learning rate scheduling\")\n",
    "print(\"‚Ä¢ Disabled mixed precision (can cause VAE issues)\")\n",
    "print(\"‚Ä¢ Reduced batch size for better gradients\")\n",
    "\n",
    "# Use smaller batch size for better VAE training\n",
    "smaller_train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=512,  # Smaller batch size for VAE\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "smaller_test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Train with improved settings\n",
    "start_time = time.time()\n",
    "\n",
    "train_losses_improved, recon_losses, kl_losses = train_vae_improved(\n",
    "    model_improved, \n",
    "    smaller_train_loader, \n",
    "    epochs=20,  # Start with fewer epochs to check\n",
    "    lr=1e-3,\n",
    "    beta=1.0,\n",
    "    use_amp=False,  # Disable mixed precision for VAE stability\n",
    "    recon_loss_type='mse',  # MSE often works better than BCE\n",
    "    warmup_epochs=5\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Plot comprehensive training metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Total loss\n",
    "axes[0, 0].plot(train_losses_improved, 'b-', linewidth=2, marker='o')\n",
    "axes[0, 0].set_title('Total VAE Loss (Improved)')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Reconstruction loss\n",
    "axes[0, 1].plot(recon_losses, 'r-', linewidth=2, marker='s')\n",
    "axes[0, 1].set_title('Reconstruction Loss (MSE)')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Reconstruction Loss')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# KL loss\n",
    "axes[1, 0].plot(kl_losses, 'g-', linewidth=2, marker='^')\n",
    "axes[1, 0].set_title('KL Divergence Loss')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('KL Loss')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss components ratio\n",
    "recon_ratio = [r / (r + k) for r, k in zip(recon_losses, kl_losses)]\n",
    "kl_ratio = [k / (r + k) for r, k in zip(recon_losses, kl_losses)]\n",
    "\n",
    "axes[1, 1].plot(recon_ratio, 'r-', linewidth=2, label='Reconstruction %')\n",
    "axes[1, 1].plot(kl_ratio, 'g-', linewidth=2, label='KL %')\n",
    "axes[1, 1].set_title('Loss Component Ratios')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Proportion')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print training summary\n",
    "print(f\"\\n‚úÖ Improved Training Complete!\")\n",
    "print(f\"Training time: {training_time:.2f} seconds\")\n",
    "print(f\"Final total loss: {train_losses_improved[-1]:.6f}\")\n",
    "print(f\"Final reconstruction loss: {recon_losses[-1]:.6f}\")\n",
    "print(f\"Final KL loss: {kl_losses[-1]:.6f}\")\n",
    "\n",
    "# Test the improved model\n",
    "print(f\"\\nüß™ Testing improved model reconstructions...\")\n",
    "model_improved.eval()\n",
    "with torch.no_grad():\n",
    "    test_batch = next(iter(smaller_test_loader))[0][:8].to(device)\n",
    "    recon_improved, mu_improved, logvar_improved = model_improved(test_batch)\n",
    "    \n",
    "    # Calculate reconstruction quality\n",
    "    mse_improved = F.mse_loss(recon_improved, test_batch, reduction='mean')\n",
    "    bce_improved = F.binary_cross_entropy(torch.clamp(recon_improved, 1e-8, 1-1e-8), \n",
    "                                         test_batch, reduction='mean')\n",
    "    \n",
    "    print(f\"Improved model MSE: {mse_improved:.6f}\")\n",
    "    print(f\"Improved model BCE: {bce_improved:.6f}\")\n",
    "    print(f\"Latent mu std: {mu_improved.std():.4f}\")\n",
    "    print(f\"Reconstruction range: [{recon_improved.min():.4f}, {recon_improved.max():.4f}]\")\n",
    "    \n",
    "    # Visual comparison\n",
    "    fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "    \n",
    "    for i in range(8):\n",
    "        # Original\n",
    "        axes[0, i].imshow(test_batch[i].cpu().squeeze(), cmap='gray')\n",
    "        axes[0, i].set_title(f'Original {i}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Improved reconstruction\n",
    "        axes[1, i].imshow(recon_improved[i].cpu().squeeze(), cmap='gray')\n",
    "        axes[1, i].set_title(f'Improved {i}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Improved VAE Reconstructions', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Compare with original model if it exists\n",
    "if 'model' in locals():\n",
    "    print(f\"\\nüìä Comparison with original model:\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        recon_original, _, _ = model(test_batch)\n",
    "        mse_original = F.mse_loss(recon_original, test_batch, reduction='mean')\n",
    "        print(f\"Original model MSE: {mse_original:.6f}\")\n",
    "        print(f\"Improved model MSE: {mse_improved:.6f}\")\n",
    "        print(f\"Improvement: {((mse_original - mse_improved) / mse_original * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the VAE model with A100 optimizations\n",
    "import time\n",
    "\n",
    "print(\"üöÄ Starting A100-optimized training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Use mixed precision training for A100 efficiency\n",
    "train_losses = train_vae(model, train_loader, epochs=10, beta=1.0, use_amp=True)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Main loss plot\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(train_losses, 'b-', linewidth=2, marker='o')\n",
    "plt.title('VAE Training Loss (A100 Optimized)', fontsize=14)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Training speed analysis\n",
    "plt.subplot(2, 2, 2)\n",
    "epochs = list(range(len(train_losses)))\n",
    "samples_processed = [(epoch + 1) * len(train_loader.dataset) for epoch in epochs]\n",
    "plt.plot(epochs, samples_processed, 'g-', linewidth=2, marker='s')\n",
    "plt.title('Samples Processed')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Total Samples')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# GPU utilization estimate (based on batch size and model size)\n",
    "plt.subplot(2, 2, 3)\n",
    "batch_sizes = [128, 512, 1024, 2048, 4096]  # Different batch sizes\n",
    "estimated_util = [min(100, (bs / 2048) * 80) for bs in batch_sizes]  # Rough estimate\n",
    "current_idx = batch_sizes.index(train_loader.batch_size) if train_loader.batch_size in batch_sizes else -1\n",
    "\n",
    "plt.bar(range(len(batch_sizes)), estimated_util, alpha=0.7, color='orange')\n",
    "if current_idx >= 0:\n",
    "    plt.bar(current_idx, estimated_util[current_idx], color='red', alpha=0.8, label='Current')\n",
    "plt.title('Estimated GPU Utilization by Batch Size')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('GPU Utilization (%)')\n",
    "plt.xticks(range(len(batch_sizes)), batch_sizes)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Performance metrics\n",
    "plt.subplot(2, 2, 4)\n",
    "metrics = ['Samples/sec', 'Batches/sec', 'Time/epoch (s)']\n",
    "total_samples = len(train_loader.dataset) * len(train_losses)\n",
    "samples_per_sec = total_samples / training_time\n",
    "batches_per_sec = len(train_loader) * len(train_losses) / training_time\n",
    "time_per_epoch = training_time / len(train_losses)\n",
    "\n",
    "values = [samples_per_sec, batches_per_sec, time_per_epoch]\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "bars = plt.bar(metrics, values, color=colors, alpha=0.7)\n",
    "plt.title('Training Performance Metrics')\n",
    "plt.ylabel('Rate')\n",
    "for bar, value in zip(bars, values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{value:.1f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comprehensive training summary\n",
    "final_loss = train_losses[-1]\n",
    "initial_loss = train_losses[0]\n",
    "improvement = initial_loss - final_loss\n",
    "\n",
    "print(f\"\\nüéØ A100 Training Performance Summary:\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Training Time: {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "print(f\"Samples/second: {samples_per_sec:.1f}\")\n",
    "print(f\"Batches/second: {batches_per_sec:.1f}\")\n",
    "print(f\"Time per epoch: {time_per_epoch:.2f} seconds\")\n",
    "print(f\"Batch size used: {train_loader.batch_size}\")\n",
    "print(f\"Total batches per epoch: {len(train_loader)}\")\n",
    "\n",
    "print(f\"\\nüìä Training Quality:\")\n",
    "print(f\"Initial Loss: {initial_loss:.6f}\")\n",
    "print(f\"Final Loss: {final_loss:.6f}\")\n",
    "print(f\"Total Improvement: {improvement:.6f}\")\n",
    "print(f\"Improvement %: {(improvement/initial_loss)*100:.2f}%\")\n",
    "\n",
    "# GPU memory usage\n",
    "if torch.cuda.is_available():\n",
    "    memory_used = torch.cuda.memory_allocated() / 1e9\n",
    "    memory_cached = torch.cuda.memory_reserved() / 1e9\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    \n",
    "    print(f\"\\nüíæ A100 Memory Usage:\")\n",
    "    print(f\"Memory allocated: {memory_used:.2f} GB\")\n",
    "    print(f\"Memory cached: {memory_cached:.2f} GB\")\n",
    "    print(f\"Total memory: {total_memory:.1f} GB\")\n",
    "    print(f\"Memory utilization: {(memory_used/total_memory)*100:.1f}%\")\n",
    "\n",
    "# Recommendations for better GPU utilization\n",
    "print(f\"\\nüí° A100 Optimization Recommendations:\")\n",
    "if train_loader.batch_size < 1024:\n",
    "    print(f\"   ‚Ä¢ ‚ö†Ô∏è  Batch size ({train_loader.batch_size}) is small for A100 - try 2048-8192\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ ‚úÖ Batch size ({train_loader.batch_size}) is good for A100\")\n",
    "\n",
    "if training_time / len(train_losses) < 5:\n",
    "    print(f\"   ‚Ä¢ ‚ö†Ô∏è  Training very fast ({time_per_epoch:.1f}s/epoch) - consider larger model or more data\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ ‚úÖ Training time per epoch is reasonable\")\n",
    "\n",
    "print(f\"   ‚Ä¢ Consider increasing model size (more layers/channels)\")\n",
    "print(f\"   ‚Ä¢ Try larger datasets (CIFAR-10, ImageNet)\")\n",
    "print(f\"   ‚Ä¢ Use gradient accumulation for even larger effective batch sizes\")\n",
    "print(f\"   ‚Ä¢ Enable model compilation (torch.compile) if PyTorch 2.0+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d034b3",
   "metadata": {},
   "source": [
    "## 3.5 VAE Quality Assessment\n",
    "\n",
    "Before proceeding with adversarial attacks, let's thoroughly evaluate the trained VAE to ensure it has learned meaningful representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e07fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_vae_reconstructions(model, test_loader, device, num_samples=10):\n",
    "    \"\"\"\n",
    "    Evaluate VAE reconstruction quality on random test samples\n",
    "    Shows original vs reconstruction side by side with reconstruction errors\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get random test samples\n",
    "    test_iter = iter(test_loader)\n",
    "    test_data, test_labels = next(test_iter)\n",
    "    \n",
    "    # Select random samples\n",
    "    indices = torch.randperm(test_data.size(0))[:num_samples]\n",
    "    sample_data = test_data[indices].to(device)\n",
    "    sample_labels = test_labels[indices]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get reconstructions\n",
    "        recon_data, mu, logvar = model(sample_data)\n",
    "        \n",
    "        # Calculate reconstruction errors\n",
    "        recon_errors = F.mse_loss(recon_data, sample_data, reduction='none')\n",
    "        recon_errors = recon_errors.view(recon_errors.size(0), -1).mean(dim=1)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(3, num_samples, figsize=(num_samples*2, 6))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original image\n",
    "        axes[0, i].imshow(sample_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "        axes[0, i].set_title(f'Original\\nDigit: {sample_labels[i].item()}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Reconstructed image\n",
    "        axes[1, i].imshow(recon_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "        axes[1, i].set_title(f'Reconstruction\\nMSE: {recon_errors[i].item():.4f}')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Difference (amplified)\n",
    "        diff = (sample_data[i] - recon_data[i]).detach().cpu().squeeze()\n",
    "        axes[2, i].imshow(diff * 5, cmap='RdBu', vmin=-1, vmax=1)\n",
    "        axes[2, i].set_title(f'Difference (√ó5)')\n",
    "        axes[2, i].axis('off')\n",
    "    \n",
    "    # Add row labels\n",
    "    axes[0, 0].set_ylabel('Original', rotation=90, labelpad=40, fontsize=12, ha='center')\n",
    "    axes[1, 0].set_ylabel('Reconstruction', rotation=90, labelpad=40, fontsize=12, ha='center')\n",
    "    axes[2, 0].set_ylabel('Difference', rotation=90, labelpad=40, fontsize=12, ha='center')\n",
    "    \n",
    "    plt.suptitle(f'VAE Reconstruction Quality Assessment ({num_samples} Random Samples)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    avg_error = recon_errors.mean().item()\n",
    "    std_error = recon_errors.std().item()\n",
    "    min_error = recon_errors.min().item()\n",
    "    max_error = recon_errors.max().item()\n",
    "    \n",
    "    print(f\"\\nüìä Reconstruction Statistics:\")\n",
    "    print(f\"Average MSE: {avg_error:.6f}\")\n",
    "    print(f\"Std Dev MSE: {std_error:.6f}\")\n",
    "    print(f\"Min MSE: {min_error:.6f}\")\n",
    "    print(f\"Max MSE: {max_error:.6f}\")\n",
    "    \n",
    "    # Analyze latent space statistics\n",
    "    with torch.no_grad():\n",
    "        mu_mean = mu.mean(dim=0)\n",
    "        mu_std = mu.std(dim=0)\n",
    "        latent_norm = torch.norm(mu, dim=1).mean()\n",
    "    \n",
    "    print(f\"\\nüß† Latent Space Statistics:\")\n",
    "    print(f\"Latent dimensions: {model.latent_dim}\")\n",
    "    print(f\"Mean latent values: [{mu_mean[0].item():.4f}, {mu_mean[1].item():.4f}]\")\n",
    "    print(f\"Std latent values: [{mu_std[0].item():.4f}, {mu_std[1].item():.4f}]\")\n",
    "    print(f\"Average latent norm: {latent_norm.item():.4f}\")\n",
    "    \n",
    "    return recon_errors, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space_grid(model, device, grid_size=15, latent_range=3):\n",
    "    \"\"\"\n",
    "    Generate and visualize a grid of samples from the latent space\n",
    "    This shows what the VAE has learned to generate across the latent space\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a grid of points in latent space\n",
    "    x = np.linspace(-latent_range, latent_range, grid_size)\n",
    "    y = np.linspace(-latent_range, latent_range, grid_size)\n",
    "    \n",
    "    # Create meshgrid\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    \n",
    "    # Flatten the grid\n",
    "    grid_points = np.column_stack([xx.ravel(), yy.ravel()])\n",
    "    \n",
    "    # Convert to tensor\n",
    "    latent_samples = torch.FloatTensor(grid_points).to(device)\n",
    "    \n",
    "    # Generate images from latent samples\n",
    "    with torch.no_grad():\n",
    "        generated_images = model.decoder(latent_samples)\n",
    "    \n",
    "    # Create the visualization\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    \n",
    "    # Create a large image by concatenating generated samples\n",
    "    img_size = 28  # MNIST image size\n",
    "    full_image = np.zeros((grid_size * img_size, grid_size * img_size))\n",
    "    \n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            idx = i * grid_size + j\n",
    "            img = generated_images[idx].cpu().squeeze().numpy()\n",
    "            \n",
    "            # Place the image in the correct position\n",
    "            start_row = i * img_size\n",
    "            end_row = start_row + img_size\n",
    "            start_col = j * img_size\n",
    "            end_col = start_col + img_size\n",
    "            \n",
    "            full_image[start_row:end_row, start_col:end_col] = img\n",
    "    \n",
    "    # Display the full image\n",
    "    ax.imshow(full_image, cmap='gray')\n",
    "    ax.set_title(f'Latent Space Manifold Visualization ({grid_size}√ó{grid_size} grid)\\n'\n",
    "                f'Range: [{-latent_range}, {latent_range}] in both dimensions', fontsize=14)\n",
    "    \n",
    "    # Add coordinate labels\n",
    "    tick_positions = np.arange(0, grid_size * img_size, img_size) + img_size // 2\n",
    "    tick_labels = [f'{val:.1f}' for val in x]\n",
    "    \n",
    "    ax.set_xticks(tick_positions[::3])  # Show every 3rd tick to avoid crowding\n",
    "    ax.set_yticks(tick_positions[::3])\n",
    "    ax.set_xticklabels(tick_labels[::3])\n",
    "    ax.set_yticklabels(tick_labels[::3])\n",
    "    \n",
    "    ax.set_xlabel('Latent Dimension 1', fontsize=12)\n",
    "    ax.set_ylabel('Latent Dimension 2', fontsize=12)\n",
    "    \n",
    "    # Add grid lines for better visualization\n",
    "    for i in range(1, grid_size):\n",
    "        ax.axhline(y=i * img_size, color='red', alpha=0.3, linewidth=0.5)\n",
    "        ax.axvline(x=i * img_size, color='red', alpha=0.3, linewidth=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Also create a smaller focused view around the center\n",
    "    center_range = 2\n",
    "    center_grid = 10\n",
    "    \n",
    "    # Create centered grid\n",
    "    x_center = np.linspace(-center_range, center_range, center_grid)\n",
    "    y_center = np.linspace(-center_range, center_range, center_grid)\n",
    "    xx_center, yy_center = np.meshgrid(x_center, y_center)\n",
    "    grid_points_center = np.column_stack([xx_center.ravel(), yy_center.ravel()])\n",
    "    latent_samples_center = torch.FloatTensor(grid_points_center).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_images_center = model.decoder(latent_samples_center)\n",
    "    \n",
    "    # Create focused visualization\n",
    "    fig, axes = plt.subplots(center_grid, center_grid, figsize=(10, 10))\n",
    "    \n",
    "    for i in range(center_grid):\n",
    "        for j in range(center_grid):\n",
    "            idx = i * center_grid + j\n",
    "            img = generated_images_center[idx].cpu().squeeze().numpy()\n",
    "            \n",
    "            axes[i, j].imshow(img, cmap='gray')\n",
    "            axes[i, j].axis('off')\n",
    "            \n",
    "            # Add coordinate labels on border\n",
    "            if i == 0:  # Top row\n",
    "                axes[i, j].set_title(f'{x_center[j]:.1f}', fontsize=8)\n",
    "            if j == 0:  # Left column\n",
    "                axes[i, j].set_ylabel(f'{y_center[i]:.1f}', fontsize=8)\n",
    "    \n",
    "    plt.suptitle(f'Focused Latent Space View (Center Region ¬±{center_range})', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"üé® Generated {grid_size*grid_size} images from latent space grid\")\n",
    "    print(f\"üìç Latent range: [{-latent_range}, {latent_range}]\")\n",
    "    print(f\"üîç Focused view range: [{-center_range}, {center_range}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate VAE Reconstruction Quality\n",
    "print(\"üîç Evaluating VAE Reconstruction Quality...\")\n",
    "recon_errors, latent_samples = evaluate_vae_reconstructions(model, test_loader, device, num_samples=10)\n",
    "\n",
    "# Check if the model has learned reasonable reconstructions\n",
    "avg_error = recon_errors.mean().item()\n",
    "if avg_error > 0.1:\n",
    "    print(f\"‚ö†Ô∏è  WARNING: High reconstruction error ({avg_error:.4f})\")\n",
    "    print(\"   Consider training for more epochs or adjusting hyperparameters\")\n",
    "elif avg_error > 0.05:\n",
    "    print(f\"‚ö†Ô∏è  MODERATE: Reconstruction error is moderate ({avg_error:.4f})\")\n",
    "    print(\"   VAE quality is acceptable but could be improved\")\n",
    "else:\n",
    "    print(f\"‚úÖ GOOD: Low reconstruction error ({avg_error:.4f})\")\n",
    "    print(\"   VAE has learned good reconstructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af18c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Latent Space Grid Visualization\n",
    "print(\"üé® Generating latent space manifold visualization...\")\n",
    "plot_latent_space_grid(model, device, grid_size=15, latent_range=3)\n",
    "\n",
    "# Additional analysis: Check latent space coverage\n",
    "with torch.no_grad():\n",
    "    # Sample from test set to see latent distribution\n",
    "    test_iter = iter(test_loader)\n",
    "    test_batch, test_batch_labels = next(test_iter)\n",
    "    test_batch = test_batch[:100].to(device)  # Use 100 samples\n",
    "    \n",
    "    mu_batch, _ = model.encoder(test_batch)\n",
    "    \n",
    "    # Calculate latent space statistics\n",
    "    latent_mean = mu_batch.mean(dim=0)\n",
    "    latent_std = mu_batch.std(dim=0)\n",
    "    latent_range_actual = [\n",
    "        (mu_batch[:, 0].min().item(), mu_batch[:, 0].max().item()),\n",
    "        (mu_batch[:, 1].min().item(), mu_batch[:, 1].max().item())\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüìä Latent Space Coverage Analysis:\")\n",
    "    print(f\"Dimension 1 - Mean: {latent_mean[0].item():.3f}, Std: {latent_std[0].item():.3f}\")\n",
    "    print(f\"Dimension 1 - Range: [{latent_range_actual[0][0]:.3f}, {latent_range_actual[0][1]:.3f}]\")\n",
    "    print(f\"Dimension 2 - Mean: {latent_mean[1].item():.3f}, Std: {latent_std[1].item():.3f}\")\n",
    "    print(f\"Dimension 2 - Range: [{latent_range_actual[1][0]:.3f}, {latent_range_actual[1][1]:.3f}]\")\n",
    "    \n",
    "    # Check if latent space is being utilized effectively\n",
    "    max_range = max(latent_range_actual[0][1] - latent_range_actual[0][0],\n",
    "                   latent_range_actual[1][1] - latent_range_actual[1][0])\n",
    "    \n",
    "    if max_range < 2:\n",
    "        print(\"‚ö†Ô∏è  Latent space utilization is limited - consider reducing regularization (Œ≤)\")\n",
    "    elif max_range > 6:\n",
    "        print(\"‚ö†Ô∏è  Latent space is very spread out - consider increasing regularization (Œ≤)\")\n",
    "    else:\n",
    "        print(\"‚úÖ Latent space utilization looks good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f721d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Sufficiency Assessment\n",
    "print(\"\\nüéØ VAE Training Sufficiency Assessment:\")\n",
    "\n",
    "# Calculate final training loss\n",
    "final_loss = train_losses[-1] if train_losses else float('inf')\n",
    "print(f\"Final training loss: {final_loss:.6f}\")\n",
    "\n",
    "# Assess training quality based on multiple metrics\n",
    "assessment_score = 0\n",
    "recommendations = []\n",
    "\n",
    "# 1. Reconstruction error assessment\n",
    "avg_recon_error = recon_errors.mean().item()\n",
    "if avg_recon_error < 0.05:\n",
    "    assessment_score += 3\n",
    "    print(\"‚úÖ Reconstruction quality: EXCELLENT\")\n",
    "elif avg_recon_error < 0.1:\n",
    "    assessment_score += 2\n",
    "    print(\"‚úÖ Reconstruction quality: GOOD\")\n",
    "elif avg_recon_error < 0.15:\n",
    "    assessment_score += 1\n",
    "    print(\"‚ö†Ô∏è  Reconstruction quality: MODERATE\")\n",
    "    recommendations.append(\"Consider training for more epochs\")\n",
    "else:\n",
    "    print(\"‚ùå Reconstruction quality: POOR\")\n",
    "    recommendations.append(\"Increase training epochs significantly\")\n",
    "\n",
    "# 2. Training loss convergence\n",
    "if len(train_losses) >= 3:\n",
    "    loss_improvement = train_losses[0] - train_losses[-1]\n",
    "    loss_stability = abs(train_losses[-1] - train_losses[-2])\n",
    "    \n",
    "    if loss_improvement > 0.01 and loss_stability < 0.001:\n",
    "        assessment_score += 3\n",
    "        print(\"‚úÖ Training convergence: EXCELLENT\")\n",
    "    elif loss_improvement > 0.005:\n",
    "        assessment_score += 2\n",
    "        print(\"‚úÖ Training convergence: GOOD\")\n",
    "    elif loss_improvement > 0.001:\n",
    "        assessment_score += 1\n",
    "        print(\"‚ö†Ô∏è  Training convergence: MODERATE\")\n",
    "        recommendations.append(\"Train for more epochs for better convergence\")\n",
    "    else:\n",
    "        print(\"‚ùå Training convergence: POOR\")\n",
    "        recommendations.append(\"Training may need more epochs or different hyperparameters\")\n",
    "\n",
    "# 3. Latent space utilization\n",
    "if max_range > 1.5 and max_range < 5:\n",
    "    assessment_score += 2\n",
    "    print(\"‚úÖ Latent space utilization: GOOD\")\n",
    "elif max_range > 0.8:\n",
    "    assessment_score += 1\n",
    "    print(\"‚ö†Ô∏è  Latent space utilization: MODERATE\")\n",
    "else:\n",
    "    print(\"‚ùå Latent space utilization: POOR\")\n",
    "    recommendations.append(\"Adjust Œ≤ parameter for better latent space usage\")\n",
    "\n",
    "# Overall assessment\n",
    "total_score = assessment_score\n",
    "max_score = 8\n",
    "\n",
    "print(f\"\\nüìä Overall VAE Quality Score: {total_score}/{max_score}\")\n",
    "\n",
    "if total_score >= 7:\n",
    "    print(\"üéâ EXCELLENT: VAE is well-trained and ready for adversarial attacks!\")\n",
    "elif total_score >= 5:\n",
    "    print(\"üëç GOOD: VAE quality is acceptable for adversarial attack analysis\")\n",
    "elif total_score >= 3:\n",
    "    print(\"‚ö†Ô∏è  MODERATE: VAE could benefit from additional training\")\n",
    "else:\n",
    "    print(\"‚ùå POOR: Consider retraining the VAE with different parameters\")\n",
    "\n",
    "if recommendations:\n",
    "    print(f\"\\nüí° Recommendations:\")\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"   {i}. {rec}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üìà If you want to improve the VAE, consider:\")\n",
    "print(\"   ‚Ä¢ Increasing epochs to 20-50\")\n",
    "print(\"   ‚Ä¢ Adjusting Œ≤ (try 0.5 for less regularization)\")\n",
    "print(\"   ‚Ä¢ Using a different learning rate (try 1e-4)\")\n",
    "print(\"   ‚Ä¢ Adding batch normalization or dropout\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56488eb3",
   "metadata": {},
   "source": [
    "## 4. Visualize Latent Space (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(model, test_loader, device, num_samples=2000):\n",
    "    \"\"\"Plot the 2D latent space representation\"\"\"\n",
    "    model.eval()\n",
    "    latents = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data = data.to(device)\n",
    "            mu, _ = model.encoder(data)\n",
    "            latents.append(mu.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "            \n",
    "            if len(latents) * data.size(0) >= num_samples:\n",
    "                break\n",
    "    \n",
    "    latents = np.concatenate(latents, axis=0)[:num_samples]\n",
    "    labels = np.concatenate(labels, axis=0)[:num_samples]\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter = plt.scatter(latents[:, 0], latents[:, 1], c=labels, cmap='tab10', alpha=0.6)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title('2D Latent Space Representation (Color = Digit Class)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return latents, labels\n",
    "\n",
    "latents, labels = plot_latent_space(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e133d24",
   "metadata": {},
   "source": [
    "## 5. Implement Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialAttacks:\n",
    "    \"\"\"Class containing various adversarial attack methods for VAEs\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def fgsm_attack(model, data, target, epsilon):\n",
    "        \"\"\"\n",
    "        Fast Gradient Sign Method (FGSM) attack\n",
    "        \n",
    "        Args:\n",
    "            model: VAE model\n",
    "            data: input data\n",
    "            target: target data (for reconstruction loss)\n",
    "            epsilon: perturbation magnitude\n",
    "        \"\"\"\n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Enable gradient computation for input\n",
    "        data.requires_grad = True\n",
    "        \n",
    "        # Forward pass\n",
    "        recon_data, mu, logvar = model(data)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = vae_loss(recon_data, target, mu, logvar)\n",
    "        \n",
    "        # Zero gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Get gradient sign\n",
    "        data_grad = data.grad.data\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        \n",
    "        # Create adversarial example\n",
    "        perturbed_data = data + epsilon * sign_data_grad\n",
    "        perturbed_data = torch.clamp(perturbed_data, 0, 1)\n",
    "        \n",
    "        return perturbed_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def pgd_attack(model, data, target, epsilon, alpha, num_iter):\n",
    "        \"\"\"\n",
    "        Projected Gradient Descent (PGD) attack\n",
    "        \n",
    "        Args:\n",
    "            model: VAE model\n",
    "            data: input data\n",
    "            target: target data\n",
    "            epsilon: maximum perturbation\n",
    "            alpha: step size\n",
    "            num_iter: number of iterations\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        # Initialize perturbation\n",
    "        delta = torch.zeros_like(data).uniform_(-epsilon, epsilon)\n",
    "        delta.requires_grad = True\n",
    "        \n",
    "        for i in range(num_iter):\n",
    "            # Forward pass with perturbation\n",
    "            perturbed_data = data + delta\n",
    "            recon_data, mu, logvar = model(perturbed_data)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = vae_loss(recon_data, target, mu, logvar)\n",
    "            \n",
    "            # Calculate gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update perturbation\n",
    "            delta.data = delta.data + alpha * delta.grad.data.sign()\n",
    "            delta.data = torch.clamp(delta.data, -epsilon, epsilon)\n",
    "            delta.data = torch.clamp(data + delta.data, 0, 1) - data\n",
    "            \n",
    "            # Zero gradients\n",
    "            delta.grad.zero_()\n",
    "        \n",
    "        return data + delta\n",
    "    \n",
    "    @staticmethod\n",
    "    def latent_space_attack(model, data, epsilon, target_latent=None):\n",
    "        \"\"\"\n",
    "        Attack in latent space by perturbing encoded representations\n",
    "        \n",
    "        Args:\n",
    "            model: VAE model\n",
    "            data: input data\n",
    "            epsilon: perturbation magnitude in latent space\n",
    "            target_latent: target latent representation (optional)\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        # Encode to latent space\n",
    "        mu, logvar = model.encoder(data)\n",
    "        z = model.reparameterize(mu, logvar)\n",
    "        \n",
    "        if target_latent is not None:\n",
    "            # Move towards target latent representation\n",
    "            direction = (target_latent - z).sign()\n",
    "            perturbed_z = z + epsilon * direction\n",
    "        else:\n",
    "            # Random perturbation in latent space\n",
    "            noise = torch.randn_like(z)\n",
    "            perturbed_z = z + epsilon * noise\n",
    "        \n",
    "        # Decode back to image space\n",
    "        adversarial_recon = model.decoder(perturbed_z)\n",
    "        \n",
    "        return adversarial_recon, z, perturbed_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce955d6",
   "metadata": {},
   "source": [
    "## 6. Demonstrate Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd32faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test samples for attacks\n",
    "test_iter = iter(test_loader)\n",
    "test_data, test_labels = next(test_iter)\n",
    "test_data = test_data[:8].to(device)  # Use first 8 samples\n",
    "\n",
    "# Initialize attack methods\n",
    "attacks = AdversarialAttacks()\n",
    "\n",
    "# Show original images\n",
    "fig, axes = plt.subplots(1, 8, figsize=(16, 2))\n",
    "for i in range(8):\n",
    "    axes[i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[i].set_title(f'Original {i}')\n",
    "    axes[i].axis('off')\n",
    "plt.suptitle('Original Test Images')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a5b21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FGSM Attack - Complete Pipeline ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'attacks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== FGSM Attack - Complete Pipeline ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m epsilon_fgsm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fgsm_adversarial \u001b[38;5;241m=\u001b[39m attacks\u001b[38;5;241m.\u001b[39mfgsm_attack(model, test_data, test_data, epsilon\u001b[38;5;241m=\u001b[39mepsilon_fgsm)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Get reconstructions\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'attacks' is not defined"
     ]
    }
   ],
   "source": [
    "# FGSM Attack - Comprehensive Analysis\n",
    "print(\"\\n=== FGSM Attack - Complete Pipeline ===\")\n",
    "epsilon_fgsm = 0.1\n",
    "fgsm_adversarial = attacks.fgsm_attack(model, test_data, test_data, epsilon=epsilon_fgsm)\n",
    "\n",
    "# Get reconstructions\n",
    "with torch.no_grad():\n",
    "    original_recon, _, _ = model(test_data)\n",
    "    adversarial_recon, _, _ = model(fgsm_adversarial)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(6, 8, figsize=(16, 12))\n",
    "row_labels = [\n",
    "    'Original Input',\n",
    "    'Original Reconstruction', \n",
    "    'Adversarial Input',\n",
    "    'Adversarial Reconstruction',\n",
    "    'Input Difference (x10)',\n",
    "    'Reconstruction Difference (x10)'\n",
    "]\n",
    "\n",
    "for i in range(8):\n",
    "    # Row 1: Original inputs\n",
    "    axes[0, i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Sample {i}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Original reconstructions\n",
    "    axes[1, i].imshow(original_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Row 3: Adversarial inputs (epsilon-perturbed)\n",
    "    axes[2, i].imshow(fgsm_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[2, i].axis('off')\n",
    "    \n",
    "    # Row 4: Adversarial reconstructions\n",
    "    axes[3, i].imshow(adversarial_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[3, i].axis('off')\n",
    "    \n",
    "    # Row 5: Input differences (original vs adversarial, amplified)\n",
    "    input_diff = (fgsm_adversarial[i] - test_data[i]).detach().cpu().squeeze()\n",
    "    axes[4, i].imshow(input_diff * 10, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[4, i].axis('off')\n",
    "    \n",
    "    # Row 6: Reconstruction differences (original recon vs adversarial recon, amplified)\n",
    "    recon_diff = (adversarial_recon[i] - original_recon[i]).detach().cpu().squeeze()\n",
    "    axes[5, i].imshow(recon_diff * 10, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[5, i].axis('off')\n",
    "\n",
    "# Add row labels\n",
    "for i, label in enumerate(row_labels):\n",
    "    axes[i, 0].set_ylabel(label, rotation=90, labelpad=50, fontsize=10, ha='center')\n",
    "\n",
    "plt.suptitle(f'FGSM Attack Analysis (Œµ={epsilon_fgsm})', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display statistics\n",
    "input_perturbation = (fgsm_adversarial - test_data).detach().cpu()\n",
    "recon_perturbation = (adversarial_recon - original_recon).detach().cpu()\n",
    "\n",
    "print(f\"\\nüìä FGSM Attack Statistics:\")\n",
    "print(f\"Input Perturbation:\")\n",
    "print(f\"  L2 norm: {torch.norm(input_perturbation).item():.6f}\")\n",
    "print(f\"  L‚àû norm: {torch.max(torch.abs(input_perturbation)).item():.6f}\")\n",
    "print(f\"  Mean absolute: {torch.mean(torch.abs(input_perturbation)).item():.6f}\")\n",
    "\n",
    "print(f\"\\nReconstruction Perturbation:\")\n",
    "print(f\"  L2 norm: {torch.norm(recon_perturbation).item():.6f}\")\n",
    "print(f\"  L‚àû norm: {torch.max(torch.abs(recon_perturbation)).item():.6f}\")\n",
    "print(f\"  Mean absolute: {torch.mean(torch.abs(recon_perturbation)).item():.6f}\")\n",
    "\n",
    "print(f\"\\nAmplification Factor: {torch.norm(recon_perturbation).item() / torch.norm(input_perturbation).item():.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11dbd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD Attack - Comprehensive Analysis\n",
    "print(\"\\n=== PGD Attack - Complete Pipeline ===\")\n",
    "epsilon_pgd = 0.1\n",
    "alpha = 0.01\n",
    "num_iter = 20\n",
    "\n",
    "pgd_adversarial = attacks.pgd_attack(model, test_data, test_data, \n",
    "                                   epsilon=epsilon_pgd, alpha=alpha, num_iter=num_iter)\n",
    "\n",
    "# Get reconstructions\n",
    "with torch.no_grad():\n",
    "    original_recon, _, _ = model(test_data)\n",
    "    pgd_adversarial_recon, _, _ = model(pgd_adversarial)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(6, 8, figsize=(16, 12))\n",
    "row_labels = [\n",
    "    'Original Input',\n",
    "    'Original Reconstruction', \n",
    "    'PGD Adversarial Input',\n",
    "    'PGD Adversarial Reconstruction',\n",
    "    'Input Difference (x10)',\n",
    "    'Reconstruction Difference (x10)'\n",
    "]\n",
    "\n",
    "for i in range(8):\n",
    "    # Row 1: Original inputs\n",
    "    axes[0, i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Sample {i}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Original reconstructions\n",
    "    axes[1, i].imshow(original_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Row 3: PGD adversarial inputs\n",
    "    axes[2, i].imshow(pgd_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[2, i].axis('off')\n",
    "    \n",
    "    # Row 4: PGD adversarial reconstructions\n",
    "    axes[3, i].imshow(pgd_adversarial_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[3, i].axis('off')\n",
    "    \n",
    "    # Row 5: Input differences (original vs PGD adversarial, amplified)\n",
    "    input_diff = (pgd_adversarial[i] - test_data[i]).detach().cpu().squeeze()\n",
    "    axes[4, i].imshow(input_diff * 10, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[4, i].axis('off')\n",
    "    \n",
    "    # Row 6: Reconstruction differences (original recon vs PGD adversarial recon, amplified)\n",
    "    recon_diff = (pgd_adversarial_recon[i] - original_recon[i]).detach().cpu().squeeze()\n",
    "    axes[5, i].imshow(recon_diff * 10, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[5, i].axis('off')\n",
    "\n",
    "# Add row labels\n",
    "for i, label in enumerate(row_labels):\n",
    "    axes[i, 0].set_ylabel(label, rotation=90, labelpad=50, fontsize=10, ha='center')\n",
    "\n",
    "plt.suptitle(f'PGD Attack Analysis (Œµ={epsilon_pgd}, Œ±={alpha}, iter={num_iter})', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display statistics\n",
    "input_perturbation_pgd = (pgd_adversarial - test_data).detach().cpu()\n",
    "recon_perturbation_pgd = (pgd_adversarial_recon - original_recon).detach().cpu()\n",
    "\n",
    "print(f\"\\nüìä PGD Attack Statistics:\")\n",
    "print(f\"Input Perturbation:\")\n",
    "print(f\"  L2 norm: {torch.norm(input_perturbation_pgd).item():.6f}\")\n",
    "print(f\"  L‚àû norm: {torch.max(torch.abs(input_perturbation_pgd)).item():.6f}\")\n",
    "print(f\"  Mean absolute: {torch.mean(torch.abs(input_perturbation_pgd)).item():.6f}\")\n",
    "\n",
    "print(f\"\\nReconstruction Perturbation:\")\n",
    "print(f\"  L2 norm: {torch.norm(recon_perturbation_pgd).item():.6f}\")\n",
    "print(f\"  L‚àû norm: {torch.max(torch.abs(recon_perturbation_pgd)).item():.6f}\")\n",
    "print(f\"  Mean absolute: {torch.mean(torch.abs(recon_perturbation_pgd)).item():.6f}\")\n",
    "\n",
    "print(f\"\\nAmplification Factor: {torch.norm(recon_perturbation_pgd).item() / torch.norm(input_perturbation_pgd).item():.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ddda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare FGSM vs PGD Attack Effects\n",
    "print(\"\\n=== FGSM vs PGD Comparison ===\")\n",
    "\n",
    "# Select first 4 samples for detailed comparison\n",
    "num_samples = 4\n",
    "fig, axes = plt.subplots(7, num_samples, figsize=(12, 14))\n",
    "\n",
    "comparison_labels = [\n",
    "    'Original Input',\n",
    "    'Original Reconstruction',\n",
    "    'FGSM Adversarial',\n",
    "    'FGSM Reconstruction', \n",
    "    'PGD Adversarial',\n",
    "    'PGD Reconstruction',\n",
    "    'FGSM vs PGD Diff (x5)'\n",
    "]\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Row 1: Original inputs\n",
    "    axes[0, i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Sample {i}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Original reconstructions\n",
    "    axes[1, i].imshow(original_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Row 3: FGSM adversarial inputs\n",
    "    axes[2, i].imshow(fgsm_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[2, i].axis('off')\n",
    "    \n",
    "    # Row 4: FGSM adversarial reconstructions\n",
    "    axes[3, i].imshow(adversarial_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[3, i].axis('off')\n",
    "    \n",
    "    # Row 5: PGD adversarial inputs\n",
    "    axes[4, i].imshow(pgd_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[4, i].axis('off')\n",
    "    \n",
    "    # Row 6: PGD adversarial reconstructions\n",
    "    axes[5, i].imshow(pgd_adversarial_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[5, i].axis('off')\n",
    "    \n",
    "    # Row 7: Difference between FGSM and PGD adversarial inputs\n",
    "    fgsm_vs_pgd_diff = (fgsm_adversarial[i] - pgd_adversarial[i]).detach().cpu().squeeze()\n",
    "    axes[6, i].imshow(fgsm_vs_pgd_diff * 5, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[6, i].axis('off')\n",
    "\n",
    "# Add row labels\n",
    "for i, label in enumerate(comparison_labels):\n",
    "    axes[i, 0].set_ylabel(label, rotation=90, labelpad=40, fontsize=9, ha='center')\n",
    "\n",
    "plt.suptitle('FGSM vs PGD Attack Comparison', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.18)\n",
    "plt.show()\n",
    "\n",
    "# Quantitative comparison\n",
    "print(f\"\\nüìà Attack Method Comparison:\")\n",
    "print(f\"{'Metric':<25} {'FGSM':<12} {'PGD':<12} {'Ratio (PGD/FGSM)':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "fgsm_input_l2 = torch.norm(input_perturbation).item()\n",
    "pgd_input_l2 = torch.norm(input_perturbation_pgd).item()\n",
    "print(f\"{'Input L2 Perturbation':<25} {fgsm_input_l2:<12.6f} {pgd_input_l2:<12.6f} {pgd_input_l2/fgsm_input_l2:<15.2f}\")\n",
    "\n",
    "fgsm_recon_l2 = torch.norm(recon_perturbation).item()\n",
    "pgd_recon_l2 = torch.norm(recon_perturbation_pgd).item()\n",
    "print(f\"{'Recon L2 Perturbation':<25} {fgsm_recon_l2:<12.6f} {pgd_recon_l2:<12.6f} {pgd_recon_l2/fgsm_recon_l2:<15.2f}\")\n",
    "\n",
    "fgsm_input_linf = torch.max(torch.abs(input_perturbation)).item()\n",
    "pgd_input_linf = torch.max(torch.abs(input_perturbation_pgd)).item()\n",
    "print(f\"{'Input L‚àû Perturbation':<25} {fgsm_input_linf:<12.6f} {pgd_input_linf:<12.6f} {pgd_input_linf/fgsm_input_linf:<15.2f}\")\n",
    "\n",
    "fgsm_recon_linf = torch.max(torch.abs(recon_perturbation)).item()\n",
    "pgd_recon_linf = torch.max(torch.abs(recon_perturbation_pgd)).item()\n",
    "print(f\"{'Recon L‚àû Perturbation':<25} {fgsm_recon_linf:<12.6f} {pgd_recon_linf:<12.6f} {pgd_recon_linf/fgsm_recon_linf:<15.2f}\")\n",
    "\n",
    "# Check if attacks are different\n",
    "attack_similarity = F.mse_loss(fgsm_adversarial, pgd_adversarial).item()\n",
    "print(f\"\\nüîç Attack Similarity (MSE between FGSM and PGD adversarial inputs): {attack_similarity:.6f}\")\n",
    "if attack_similarity < 1e-6:\n",
    "    print(\"‚ö†Ô∏è  Warning: FGSM and PGD attacks produced nearly identical results!\")\n",
    "else:\n",
    "    print(\"‚úì FGSM and PGD attacks produced different adversarial examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357dff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Space Attack\n",
    "print(\"\\n=== Latent Space Attack ===\")\n",
    "epsilon_latent = 2.0\n",
    "\n",
    "latent_adversarial, orig_latent, perturbed_latent = attacks.latent_space_attack(\n",
    "    model, test_data, epsilon=epsilon_latent)\n",
    "\n",
    "# Get original reconstructions for comparison\n",
    "with torch.no_grad():\n",
    "    original_recon, _, _ = model(test_data)\n",
    "\n",
    "# Visualize latent space attack results\n",
    "fig, axes = plt.subplots(3, 8, figsize=(16, 6))\n",
    "for i in range(8):\n",
    "    # Original\n",
    "    axes[0, i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Original {i}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Original reconstruction\n",
    "    axes[1, i].imshow(original_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[1, i].set_title(f'Original Recon')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Latent attack result\n",
    "    axes[2, i].imshow(latent_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[2, i].set_title(f'Latent Attack')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.suptitle(f'Latent Space Attack Results (Œµ={epsilon_latent})')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show latent space perturbations\n",
    "print(f\"Latent space perturbation magnitude: {torch.norm(perturbed_latent - orig_latent).item():.6f}\")\n",
    "print(f\"Original latent mean: {orig_latent.mean(dim=0).detach().cpu().numpy()}\")\n",
    "print(f\"Perturbed latent mean: {perturbed_latent.mean(dim=0).detach().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e08762",
   "metadata": {},
   "source": [
    "## 7. Evaluate Attack Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack_effectiveness(model, original, adversarial, attack_name):\n",
    "    \"\"\"Evaluate the effectiveness of adversarial attacks\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Reconstruct original\n",
    "        recon_orig, mu_orig, logvar_orig = model(original)\n",
    "        \n",
    "        # Reconstruct adversarial\n",
    "        recon_adv, mu_adv, logvar_adv = model(adversarial)\n",
    "        \n",
    "        # Calculate reconstruction errors\n",
    "        orig_error = F.mse_loss(recon_orig, original).item()\n",
    "        adv_error = F.mse_loss(recon_adv, adversarial).item()\n",
    "        \n",
    "        # Calculate latent space distances\n",
    "        latent_distance = F.mse_loss(mu_orig, mu_adv).item()\n",
    "        \n",
    "        # Calculate input perturbation\n",
    "        input_perturbation = F.mse_loss(original, adversarial).item()\n",
    "        \n",
    "        print(f\"\\n=== {attack_name} Effectiveness ===\")\n",
    "        print(f\"Original Reconstruction Error: {orig_error:.6f}\")\n",
    "        print(f\"Adversarial Reconstruction Error: {adv_error:.6f}\")\n",
    "        print(f\"Latent Space Distance: {latent_distance:.6f}\")\n",
    "        print(f\"Input Perturbation (MSE): {input_perturbation:.6f}\")\n",
    "        \n",
    "        return orig_error, adv_error, latent_distance, input_perturbation\n",
    "\n",
    "# Evaluate all attacks\n",
    "fgsm_results = evaluate_attack_effectiveness(model, test_data, fgsm_adversarial, \"FGSM\")\n",
    "pgd_results = evaluate_attack_effectiveness(model, test_data, pgd_adversarial, \"PGD\")\n",
    "\n",
    "# For latent attack, compare original reconstruction vs latent attack result\n",
    "with torch.no_grad():\n",
    "    orig_recon, orig_mu, orig_logvar = model(test_data)\n",
    "    latent_mse = F.mse_loss(orig_recon, latent_adversarial).item()\n",
    "    print(f\"\\n=== Latent Space Attack Effectiveness ===\")\n",
    "    print(f\"Original vs Latent Attack Reconstruction MSE: {latent_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c622df4",
   "metadata": {},
   "source": [
    "## 8. Robustness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test robustness across different epsilon values\n",
    "print(\"\\n=== Robustness Analysis ===\")\n",
    "epsilons = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "fgsm_errors = []\n",
    "pgd_errors = []\n",
    "perturbation_magnitudes = []\n",
    "\n",
    "for eps in tqdm(epsilons, desc=\"Testing epsilon values\"):\n",
    "    # FGSM\n",
    "    fgsm_adv = attacks.fgsm_attack(model, test_data, test_data, epsilon=eps)\n",
    "    _, fgsm_error, _, fgsm_pert = evaluate_attack_effectiveness(model, test_data, fgsm_adv, f\"FGSM-{eps}\")\n",
    "    fgsm_errors.append(fgsm_error)\n",
    "    \n",
    "    # PGD\n",
    "    pgd_adv = attacks.pgd_attack(model, test_data, test_data, epsilon=eps, alpha=0.01, num_iter=10)\n",
    "    _, pgd_error, _, pgd_pert = evaluate_attack_effectiveness(model, test_data, pgd_adv, f\"PGD-{eps}\")\n",
    "    pgd_errors.append(pgd_error)\n",
    "    \n",
    "    perturbation_magnitudes.append(eps)\n",
    "\n",
    "# Plot robustness curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epsilons, fgsm_errors, 'o-', label='FGSM', linewidth=2)\n",
    "plt.plot(epsilons, pgd_errors, 's-', label='PGD', linewidth=2)\n",
    "plt.xlabel('Epsilon (Perturbation Magnitude)')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('VAE Robustness vs Perturbation Magnitude')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Test different latent space perturbation magnitudes\n",
    "latent_epsilons = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "latent_errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    orig_recon, _, _ = model(test_data)\n",
    "\n",
    "for eps in latent_epsilons:\n",
    "    latent_adv, _, _ = attacks.latent_space_attack(model, test_data, epsilon=eps)\n",
    "    error = F.mse_loss(orig_recon, latent_adv).item()\n",
    "    latent_errors.append(error)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(latent_epsilons, latent_errors, '^-', color='green', linewidth=2)\n",
    "plt.xlabel('Latent Space Perturbation Magnitude')\n",
    "plt.ylabel('Reconstruction Difference (MSE)')\n",
    "plt.title('Latent Space Attack Effectiveness')\n",
    "plt.grid(True)\n",
    "\n",
    "# Compare attack methods\n",
    "plt.subplot(1, 3, 3)\n",
    "methods = ['Original', 'FGSM\\n(Œµ=0.1)', 'PGD\\n(Œµ=0.1)', 'Latent\\n(Œµ=2.0)']\n",
    "errors = [fgsm_results[0], fgsm_results[1], pgd_results[1], latent_mse]\n",
    "colors = ['blue', 'red', 'orange', 'green']\n",
    "\n",
    "bars = plt.bar(methods, errors, color=colors, alpha=0.7)\n",
    "plt.ylabel('Reconstruction Error / MSE')\n",
    "plt.title('Attack Method Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, error in zip(bars, errors):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.0001, \n",
    "             f'{error:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8d0715",
   "metadata": {},
   "source": [
    "## 9. Visualize Latent Space Perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e71041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how attacks affect the latent space\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get latent representations\n",
    "    mu_orig, _ = model.encoder(test_data[:4])\n",
    "    mu_fgsm, _ = model.encoder(fgsm_adversarial[:4])\n",
    "    mu_pgd, _ = model.encoder(pgd_adversarial[:4])\n",
    "\n",
    "# Plot latent space movements\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "for i in range(4):\n",
    "    # Original point\n",
    "    plt.scatter(mu_orig[i, 0].cpu(), mu_orig[i, 1].cpu(), \n",
    "               color=colors[i], s=100, marker='o', label=f'Original {i}' if i < 4 else \"\")\n",
    "    \n",
    "    # FGSM point\n",
    "    plt.scatter(mu_fgsm[i, 0].cpu(), mu_fgsm[i, 1].cpu(), \n",
    "               color=colors[i], s=100, marker='x', alpha=0.7)\n",
    "    \n",
    "    # PGD point\n",
    "    plt.scatter(mu_pgd[i, 0].cpu(), mu_pgd[i, 1].cpu(), \n",
    "               color=colors[i], s=100, marker='^', alpha=0.7)\n",
    "    \n",
    "    # Draw arrows showing movement\n",
    "    plt.arrow(mu_orig[i, 0].cpu(), mu_orig[i, 1].cpu(),\n",
    "             mu_fgsm[i, 0].cpu() - mu_orig[i, 0].cpu(),\n",
    "             mu_fgsm[i, 1].cpu() - mu_orig[i, 1].cpu(),\n",
    "             color=colors[i], alpha=0.5, head_width=0.1, linestyle='--')\n",
    "    \n",
    "    plt.arrow(mu_orig[i, 0].cpu(), mu_orig[i, 1].cpu(),\n",
    "             mu_pgd[i, 0].cpu() - mu_orig[i, 0].cpu(),\n",
    "             mu_pgd[i, 1].cpu() - mu_orig[i, 1].cpu(),\n",
    "             color=colors[i], alpha=0.5, head_width=0.1, linestyle='-')\n",
    "\n",
    "# Create custom legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='black', markersize=8, label='Original'),\n",
    "    Line2D([0], [0], marker='x', color='w', markerfacecolor='black', markersize=8, label='FGSM'),\n",
    "    Line2D([0], [0], marker='^', color='w', markerfacecolor='black', markersize=8, label='PGD'),\n",
    "    Line2D([0], [0], color='black', linestyle='--', label='FGSM Movement'),\n",
    "    Line2D([0], [0], color='black', linestyle='-', label='PGD Movement')\n",
    "]\n",
    "\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.title('Latent Space Perturbations from Adversarial Attacks')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814084bb",
   "metadata": {},
   "source": [
    "## 10. Defense Mechanisms (Bonus)\n",
    "\n",
    "Here are some strategies to improve VAE robustness against adversarial attacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd7e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_training_step(model, data, optimizer, epsilon=0.1, alpha=0.01):\n",
    "    \"\"\"\n",
    "    Single step of adversarial training\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # Generate adversarial examples\n",
    "    model.eval()\n",
    "    adv_data = AdversarialAttacks.fgsm_attack(model, data, data, epsilon)\n",
    "    model.train()\n",
    "    \n",
    "    # Train on both clean and adversarial data\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Clean loss\n",
    "    recon_clean, mu_clean, logvar_clean = model(data)\n",
    "    clean_loss = vae_loss(recon_clean, data, mu_clean, logvar_clean)\n",
    "    \n",
    "    # Adversarial loss\n",
    "    recon_adv, mu_adv, logvar_adv = model(adv_data)\n",
    "    adv_loss = vae_loss(recon_adv, adv_data, mu_adv, logvar_adv)\n",
    "    \n",
    "    # Combined loss\n",
    "    total_loss = 0.5 * clean_loss + 0.5 * adv_loss\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return total_loss.item()\n",
    "\n",
    "print(\"Defense Strategies for VAEs:\")\n",
    "print(\"1. Adversarial Training: Train on both clean and adversarial examples\")\n",
    "print(\"2. Input Preprocessing: Add noise or apply transformations\")\n",
    "print(\"3. Regularization: Increase Œ≤ in Œ≤-VAE to enforce stronger regularization\")\n",
    "print(\"4. Ensemble Methods: Use multiple VAE models and average predictions\")\n",
    "print(\"5. Certified Defenses: Use techniques like randomized smoothing\")\n",
    "\n",
    "# Example: Train a model with higher Œ≤ for better regularization\n",
    "robust_model = VAE(latent_dim=2)\n",
    "print(\"\\nTraining a more robust VAE with Œ≤=5.0...\")\n",
    "robust_losses = train_vae(robust_model, train_loader, epochs=5, beta=5.0)\n",
    "\n",
    "# Test robustness of the new model\n",
    "print(\"\\nTesting robustness of Œ≤-VAE:\")\n",
    "robust_fgsm = attacks.fgsm_attack(robust_model, test_data, test_data, epsilon=0.1)\n",
    "evaluate_attack_effectiveness(robust_model, test_data, robust_fgsm, \"Robust Œ≤-VAE FGSM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dbe769",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated several key concepts in adversarial attacks on VAEs:\n",
    "\n",
    "### Attack Methods:\n",
    "1. **FGSM (Fast Gradient Sign Method)**: Single-step attack using gradient sign\n",
    "2. **PGD (Projected Gradient Descent)**: Multi-step iterative attack\n",
    "3. **Latent Space Attack**: Perturbations in the encoded latent representation\n",
    "\n",
    "### Key Findings:\n",
    "- VAEs are vulnerable to adversarial perturbations in both input and latent spaces\n",
    "- Small input perturbations can cause significant changes in latent representations\n",
    "- The 2D latent space makes visualization of attack effects possible\n",
    "- Different attack methods have varying effectiveness\n",
    "\n",
    "### Defense Strategies:\n",
    "- Adversarial training with mixed clean/adversarial data\n",
    "- Stronger regularization (higher Œ≤ in Œ≤-VAE)\n",
    "- Input preprocessing and ensemble methods\n",
    "- Certified defense techniques\n",
    "\n",
    "This framework can be extended to other autoencoder architectures and datasets to study adversarial robustness in generative models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
