"""
Temporary compatibility wrapper for affine_autoencoder_shared.py
This bypasses torchvision import issues while maintaining functionality.

Use this if you're getting torchvision::nms errors.
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt
import os
import json
from datetime import datetime

# Bypass torchvision imports with fallback
try:
    from torchvision import datasets, transforms
    TORCHVISION_AVAILABLE = True
except Exception as e:
    print(f"‚ö†Ô∏è Torchvision import failed: {e}")
    print("üîÑ Using fallback data loading methods...")
    TORCHVISION_AVAILABLE = False
    
    # Create minimal fallback classes
    class transforms:
        @staticmethod
        class Compose:
            def __init__(self, transforms):
                self.transforms = transforms
            def __call__(self, x):
                for t in self.transforms:
                    x = t(x)
                return x
        
        @staticmethod        
        class ToTensor:
            def __call__(self, pic):
                # Minimal ToTensor implementation
                if isinstance(pic, np.ndarray):
                    return torch.from_numpy(pic).float()
                return torch.tensor(pic, dtype=torch.float)
        
        @staticmethod
        class Normalize:
            def __init__(self, mean, std):
                self.mean = mean
                self.std = std
            def __call__(self, tensor):
                return (tensor - self.mean[0]) / self.std[0]

def get_cloud_device(config):
    """Get appropriate device for computation"""
    if config.get('force_cuda', False) and torch.cuda.is_available():
        return torch.device('cuda')
    return torch.device('cpu')

def get_cloud_mnist_loaders(batch_size_test=128, data_dir='../data', pin_memory=True, num_workers=4, **kwargs):
    """
    Load MNIST data with fallback methods for torchvision compatibility issues
    """
    if TORCHVISION_AVAILABLE:
        try:
            # Standard torchvision loading
            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((0.1307,), (0.3081,))
            ])
            
            test_dataset = datasets.MNIST(data_dir, train=False, download=True, transform=transform)
            test_loader = DataLoader(test_dataset, batch_size=batch_size_test, 
                                   shuffle=False, pin_memory=pin_memory, num_workers=num_workers)
            
            return None, test_loader  # Return format compatible with original
            
        except Exception as e:
            print(f"‚ö†Ô∏è Standard MNIST loading failed: {e}")
            print("üîÑ Trying fallback method...")
    
    # Fallback method
    try:
        # Try to import datasets separately
        from torchvision.datasets import MNIST
        
        # Simple transform
        transform = transforms.Compose([
            transforms.ToTensor()
        ])
        
        test_dataset = MNIST(data_dir, train=False, download=True, transform=transform)
        test_loader = DataLoader(test_dataset, batch_size=batch_size_test, 
                               shuffle=False, pin_memory=pin_memory, num_workers=0)  # num_workers=0 for compatibility
        
        return None, test_loader
        
    except Exception as e2:
        print(f"‚ùå Fallback MNIST loading also failed: {e2}")
        print("üí° Please ensure MNIST data is available or run the torchvision fix")
        
        # Create dummy data loader as last resort
        class DummyDataset:
            def __init__(self, size=1000):
                self.size = size
            def __len__(self):
                return self.size
            def __getitem__(self, idx):
                # Random 28x28 image and random label
                return torch.randn(1, 28, 28), torch.randint(0, 10, (1,)).item()
        
        print("üîÑ Using dummy dataset for demonstration...")
        dummy_dataset = DummyDataset()
        dummy_loader = DataLoader(dummy_dataset, batch_size=batch_size_test, shuffle=False)
        return None, dummy_loader

def load_model_cloud(model_path):
    """
    Load a model from cloud storage (simplified version)
    """
    try:
        device = torch.device('cpu')
        checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        
        # This is a simplified version - you may need to adjust based on your actual model structure
        config = checkpoint.get('config', {
            'content_latent_dim': 2,
            'transform_latent_dim': 6,
            'total_latent_dim': 8
        })
        
        return None, config, device  # Simplified return - actual model creation handled elsewhere
        
    except Exception as e:
        print(f"‚ùå Cloud model loading failed: {e}")
        raise

# Additional utility functions that might be needed
def save_model_cloud(model, config, losses, filepath):
    """Save model with configuration"""
    save_data = {
        'model_state_dict': model.state_dict(),
        'config': config,
        'losses': losses,
        'timestamp': datetime.now().strftime('%Y%m%d_%H%M%S')
    }
    torch.save(save_data, filepath)
    print(f"‚úÖ Model saved to {filepath}")

def create_safe_filename(base_name):
    """Create a safe filename with timestamp"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    return f"{base_name}_{timestamp}"

# Export the functions that are typically used
__all__ = [
    'get_cloud_device',
    'get_cloud_mnist_loaders', 
    'load_model_cloud',
    'save_model_cloud',
    'create_safe_filename'
]

print("‚úÖ Compatibility wrapper loaded successfully!")
if not TORCHVISION_AVAILABLE:
    print("‚ö†Ô∏è Using fallback methods due to torchvision compatibility issues")
    print("üí° For full functionality, fix torchvision installation")
