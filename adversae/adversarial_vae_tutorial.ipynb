{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a67261a",
   "metadata": {},
   "source": [
    "# Adversarial Attacks on Variational Autoencoders\n",
    "\n",
    "This notebook demonstrates how to engineer adversarial attacks against a VAE using MNIST dataset with LeNet-style encoder/decoder and 2D latent space.\n",
    "\n",
    "## Key Concepts:\n",
    "- **FGSM (Fast Gradient Sign Method)**: Single-step attack using gradient sign\n",
    "- **PGD (Projected Gradient Descent)**: Multi-step iterative attack\n",
    "- **Latent Space Attack**: Attack in the encoded latent representation\n",
    "- **VAE Vulnerabilities**: How reconstruction and regularization losses affect robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d676d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision numpy matplotlib tqdm psutil\n",
    "\n",
    "# Install GPU monitoring tools (optional - will fallback to nvidia-smi if not available)\n",
    "try:\n",
    "    !pip install nvidia-ml-py\n",
    "    print(\"✓ nvidia-ml-py installed for efficient GPU monitoring\")\n",
    "except:\n",
    "    print(\"⚠ nvidia-ml-py not available, will use nvidia-smi fallback\")\n",
    "\n",
    "# Check if nvidia-smi is available\n",
    "import subprocess\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi', '--version'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✓ nvidia-smi available for GPU monitoring\")\n",
    "    else:\n",
    "        print(\"⚠ nvidia-smi not available - GPU monitoring will show zeros\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠ nvidia-smi not found - GPU monitoring will show zeros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25cd069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e1ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Monitoring utilities\n",
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "from collections import deque\n",
    "import psutil\n",
    "\n",
    "# For real-time plotting\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "class GPUMonitor:\n",
    "    \"\"\"Real-time GPU monitoring during training\"\"\"\n",
    "    \n",
    "    def __init__(self, max_points=100):\n",
    "        self.max_points = max_points\n",
    "        self.gpu_utilization = deque(maxlen=max_points)\n",
    "        self.gpu_memory = deque(maxlen=max_points)\n",
    "        self.gpu_temperature = deque(maxlen=max_points)\n",
    "        self.timestamps = deque(maxlen=max_points)\n",
    "        self.monitoring = False\n",
    "        self.monitor_thread = None\n",
    "        \n",
    "    def get_gpu_stats(self):\n",
    "        \"\"\"Get GPU statistics using nvidia-ml-py or nvidia-smi\"\"\"\n",
    "        try:\n",
    "            # Try using nvidia-ml-py first (more efficient)\n",
    "            import pynvml\n",
    "            pynvml.nvmlInit()\n",
    "            handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "            \n",
    "            # Get utilization\n",
    "            util = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "            gpu_util = util.gpu\n",
    "            \n",
    "            # Get memory info\n",
    "            mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "            memory_used = (mem_info.used / mem_info.total) * 100\n",
    "            \n",
    "            # Get temperature\n",
    "            temp = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)\n",
    "            \n",
    "            return gpu_util, memory_used, temp\n",
    "            \n",
    "        except ImportError:\n",
    "            # Fallback to nvidia-smi command\n",
    "            try:\n",
    "                result = subprocess.run([\n",
    "                    'nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu',\n",
    "                    '--format=csv,noheader,nounits'\n",
    "                ], capture_output=True, text=True, timeout=5)\n",
    "                \n",
    "                if result.returncode == 0:\n",
    "                    values = result.stdout.strip().split(',')\n",
    "                    gpu_util = float(values[0])\n",
    "                    memory_used = (float(values[1]) / float(values[2])) * 100\n",
    "                    temp = float(values[3])\n",
    "                    return gpu_util, memory_used, temp\n",
    "                    \n",
    "            except (subprocess.TimeoutExpired, FileNotFoundError, ValueError):\n",
    "                pass\n",
    "                \n",
    "        # Return zeros if no GPU monitoring available\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    def monitor_loop(self, interval=1.0):\n",
    "        \"\"\"Background monitoring loop\"\"\"\n",
    "        while self.monitoring:\n",
    "            gpu_util, memory_used, temp = self.get_gpu_stats()\n",
    "            current_time = time.time()\n",
    "            \n",
    "            self.gpu_utilization.append(gpu_util)\n",
    "            self.gpu_memory.append(memory_used)\n",
    "            self.gpu_temperature.append(temp)\n",
    "            self.timestamps.append(current_time)\n",
    "            \n",
    "            time.sleep(interval)\n",
    "    \n",
    "    def start_monitoring(self, interval=1.0):\n",
    "        \"\"\"Start GPU monitoring in background thread\"\"\"\n",
    "        if not self.monitoring:\n",
    "            self.monitoring = True\n",
    "            self.monitor_thread = threading.Thread(target=self.monitor_loop, args=(interval,))\n",
    "            self.monitor_thread.daemon = True\n",
    "            self.monitor_thread.start()\n",
    "            print(\"GPU monitoring started...\")\n",
    "    \n",
    "    def stop_monitoring(self):\n",
    "        \"\"\"Stop GPU monitoring\"\"\"\n",
    "        self.monitoring = False\n",
    "        if self.monitor_thread:\n",
    "            self.monitor_thread.join(timeout=2)\n",
    "        print(\"GPU monitoring stopped.\")\n",
    "    \n",
    "    def plot_stats(self, figsize=(15, 10)):\n",
    "        \"\"\"Plot current GPU statistics\"\"\"\n",
    "        if len(self.timestamps) == 0:\n",
    "            print(\"No monitoring data available. Start monitoring first.\")\n",
    "            return\n",
    "            \n",
    "        fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "        \n",
    "        # Convert timestamps to relative time\n",
    "        if len(self.timestamps) > 0:\n",
    "            start_time = self.timestamps[0]\n",
    "            times = [(t - start_time) / 60 for t in self.timestamps]  # Convert to minutes\n",
    "        else:\n",
    "            times = []\n",
    "        \n",
    "        # GPU Utilization\n",
    "        axes[0, 0].plot(times, list(self.gpu_utilization), 'b-', linewidth=2)\n",
    "        axes[0, 0].set_title('GPU Utilization (%)')\n",
    "        axes[0, 0].set_xlabel('Time (minutes)')\n",
    "        axes[0, 0].set_ylabel('Utilization (%)')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        axes[0, 0].set_ylim(0, 100)\n",
    "        \n",
    "        # GPU Memory Usage\n",
    "        axes[0, 1].plot(times, list(self.gpu_memory), 'r-', linewidth=2)\n",
    "        axes[0, 1].set_title('GPU Memory Usage (%)')\n",
    "        axes[0, 1].set_xlabel('Time (minutes)')\n",
    "        axes[0, 1].set_ylabel('Memory (%)')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        axes[0, 1].set_ylim(0, 100)\n",
    "        \n",
    "        # GPU Temperature\n",
    "        axes[1, 0].plot(times, list(self.gpu_temperature), 'g-', linewidth=2)\n",
    "        axes[1, 0].set_title('GPU Temperature (°C)')\n",
    "        axes[1, 0].set_xlabel('Time (minutes)')\n",
    "        axes[1, 0].set_ylabel('Temperature (°C)')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Summary statistics\n",
    "        if len(self.gpu_utilization) > 0:\n",
    "            avg_util = sum(self.gpu_utilization) / len(self.gpu_utilization)\n",
    "            max_util = max(self.gpu_utilization)\n",
    "            avg_mem = sum(self.gpu_memory) / len(self.gpu_memory)\n",
    "            max_mem = max(self.gpu_memory)\n",
    "            avg_temp = sum(self.gpu_temperature) / len(self.gpu_temperature)\n",
    "            max_temp = max(self.gpu_temperature)\n",
    "            \n",
    "            summary_text = f\"\"\"GPU Statistics Summary:\n",
    "            \n",
    "Average Utilization: {avg_util:.1f}%\n",
    "Peak Utilization: {max_util:.1f}%\n",
    "\n",
    "Average Memory: {avg_mem:.1f}%\n",
    "Peak Memory: {max_mem:.1f}%\n",
    "\n",
    "Average Temperature: {avg_temp:.1f}°C\n",
    "Peak Temperature: {max_temp:.1f}°C\n",
    "\n",
    "Monitoring Duration: {times[-1]:.1f} minutes\"\"\"\n",
    "            \n",
    "            axes[1, 1].text(0.05, 0.95, summary_text, transform=axes[1, 1].transAxes,\n",
    "                           verticalalignment='top', fontfamily='monospace', fontsize=10)\n",
    "            axes[1, 1].set_xlim(0, 1)\n",
    "            axes[1, 1].set_ylim(0, 1)\n",
    "            axes[1, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Initialize GPU monitor\n",
    "gpu_monitor = GPUMonitor()\n",
    "\n",
    "# Check if GPU is available and print initial stats\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "    # Get initial GPU stats\n",
    "    initial_util, initial_mem, initial_temp = gpu_monitor.get_gpu_stats()\n",
    "    print(f\"Initial GPU Utilization: {initial_util}%\")\n",
    "    print(f\"Initial GPU Memory Usage: {initial_mem:.1f}%\")\n",
    "    print(f\"Initial GPU Temperature: {initial_temp}°C\")\n",
    "else:\n",
    "    print(\"No GPU available - monitoring will show zeros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20929af",
   "metadata": {},
   "source": [
    "## 1. Define VAE Architecture with LeNet-style Encoder/Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetEncoder(nn.Module):\n",
    "    \"\"\"LeNet-style encoder for VAE\"\"\"\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super(LeNetEncoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Convolutional layers (LeNet-style)\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)  # 28x28 -> 28x28\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # 28x28 -> 14x14\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)  # 14x14 -> 10x10\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # 10x10 -> 5x5\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        \n",
    "        # Output layers for mean and log variance\n",
    "        self.fc_mu = nn.Linear(84, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(84, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Output mean and log variance\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5158fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetDecoder(nn.Module):\n",
    "    \"\"\"LeNet-style decoder for VAE\"\"\"\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super(LeNetDecoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(latent_dim, 84)\n",
    "        self.fc2 = nn.Linear(84, 120)\n",
    "        self.fc3 = nn.Linear(120, 16 * 5 * 5)\n",
    "        \n",
    "        # Transposed convolutional layers (reverse of encoder)\n",
    "        self.deconv1 = nn.ConvTranspose2d(16, 6, kernel_size=5, stride=2, padding=2, output_padding=1)  # 5x5 -> 10x10\n",
    "        self.deconv2 = nn.ConvTranspose2d(6, 1, kernel_size=5, stride=2, padding=2, output_padding=1)   # 10x10 -> 20x20\n",
    "        # Add padding to get from 20x20 to 28x28\n",
    "        self.final_conv = nn.ConvTranspose2d(1, 1, kernel_size=9, stride=1, padding=0)  # 20x20 -> 28x28\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(z))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        # Reshape to feature maps\n",
    "        x = x.view(-1, 16, 5, 5)\n",
    "        \n",
    "        # Transposed convolutional layers\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = torch.sigmoid(self.final_conv(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7341240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"Variational Autoencoder with LeNet-style architecture\"\"\"\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = LeNetEncoder(latent_dim)\n",
    "        self.decoder = LeNetDecoder(latent_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Reparameterization trick\"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decoder(z)\n",
    "        return recon_x, mu, logvar\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input to latent space\"\"\"\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return self.reparameterize(mu, logvar)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode from latent space\"\"\"\n",
    "        return self.decoder(z)\n",
    "\n",
    "def vae_loss(recon_x, x, mu, logvar, beta=1.0):\n",
    "    \"\"\"VAE loss function with KL divergence\"\"\"\n",
    "    # Reconstruction loss\n",
    "    recon_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    \n",
    "    # KL divergence loss\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return recon_loss + beta * kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667618d6",
   "metadata": {},
   "source": [
    "## 2. Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980fbb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Visualize some samples\n",
    "def show_samples(loader, num_samples=8):\n",
    "    data_iter = iter(loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(12, 2))\n",
    "    for i in range(num_samples):\n",
    "        axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Label: {labels[i]}')\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90f158",
   "metadata": {},
   "source": [
    "## 3. Train the VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, train_loader, epochs=10, lr=1e-3, beta=1.0, monitor_gpu=True):\n",
    "    \"\"\"Train the VAE model with optional GPU monitoring\"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    # Start GPU monitoring if requested and GPU is available\n",
    "    if monitor_gpu and torch.cuda.is_available():\n",
    "        gpu_monitor.start_monitoring(interval=0.5)  # Monitor every 0.5 seconds\n",
    "    \n",
    "    print(\"Training VAE...\")\n",
    "    try:\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            epoch_loss = 0\n",
    "            for batch_idx, (data, _) in enumerate(train_loader):\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                recon_batch, mu, logvar = model(data)\n",
    "                loss = vae_loss(recon_batch, data, mu, logvar, beta)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                # Optional: Print GPU stats every 100 batches\n",
    "                if monitor_gpu and torch.cuda.is_available() and batch_idx % 100 == 0:\n",
    "                    gpu_util, gpu_mem, gpu_temp = gpu_monitor.get_gpu_stats()\n",
    "                    if batch_idx == 0 and epoch == 0:  # Print header once\n",
    "                        print(f\"\\nBatch | GPU Util | GPU Mem | GPU Temp | Loss\")\n",
    "                        print(\"-\" * 50)\n",
    "                    if epoch % 2 == 0:  # Only print for even epochs to reduce clutter\n",
    "                        print(f\"{batch_idx:5d} | {gpu_util:7.1f}% | {gpu_mem:6.1f}% | {gpu_temp:7.1f}°C | {loss.item():.4f}\")\n",
    "            \n",
    "            avg_loss = epoch_loss / len(train_loader.dataset)\n",
    "            train_losses.append(avg_loss)\n",
    "            \n",
    "            if epoch % 2 == 0:\n",
    "                print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}')\n",
    "                \n",
    "    finally:\n",
    "        # Stop monitoring when training is done or interrupted\n",
    "        if monitor_gpu and torch.cuda.is_available():\n",
    "            gpu_monitor.stop_monitoring()\n",
    "    \n",
    "    return train_losses\n",
    "\n",
    "# Alternative: Manual GPU monitoring during training\n",
    "# If you want to monitor GPU in real-time, run this cell\n",
    "\n",
    "# Initialize and train model\n",
    "model = VAE(latent_dim=2)\n",
    "\n",
    "# Simple training without monitoring (original version)\n",
    "# train_losses = train_vae(model, train_loader, epochs=10, beta=1.0, monitor_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train model with GPU monitoring\n",
    "model = VAE(latent_dim=2)\n",
    "\n",
    "# Train with GPU monitoring enabled\n",
    "train_losses = train_vae(model, train_loader, epochs=10, beta=1.0, monitor_gpu=True)\n",
    "\n",
    "# Plot training loss and GPU statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Training loss\n",
    "axes[0, 0].plot(train_losses, 'b-', linewidth=2)\n",
    "axes[0, 0].set_title('VAE Training Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Show GPU monitoring results if available\n",
    "if torch.cuda.is_available() and len(gpu_monitor.timestamps) > 0:\n",
    "    # Convert timestamps to relative time in minutes\n",
    "    start_time = gpu_monitor.timestamps[0]\n",
    "    times = [(t - start_time) / 60 for t in gpu_monitor.timestamps]\n",
    "    \n",
    "    # GPU Utilization\n",
    "    axes[0, 1].plot(times, list(gpu_monitor.gpu_utilization), 'r-', linewidth=2)\n",
    "    axes[0, 1].set_title('GPU Utilization During Training')\n",
    "    axes[0, 1].set_xlabel('Time (minutes)')\n",
    "    axes[0, 1].set_ylabel('GPU Utilization (%)')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_ylim(0, 100)\n",
    "    \n",
    "    # GPU Memory Usage\n",
    "    axes[1, 0].plot(times, list(gpu_monitor.gpu_memory), 'g-', linewidth=2)\n",
    "    axes[1, 0].set_title('GPU Memory Usage During Training')\n",
    "    axes[1, 0].set_xlabel('Time (minutes)')\n",
    "    axes[1, 0].set_ylabel('GPU Memory (%)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_ylim(0, 100)\n",
    "    \n",
    "    # GPU Temperature\n",
    "    axes[1, 1].plot(times, list(gpu_monitor.gpu_temperature), 'orange', linewidth=2)\n",
    "    axes[1, 1].set_title('GPU Temperature During Training')\n",
    "    axes[1, 1].set_xlabel('Time (minutes)')\n",
    "    axes[1, 1].set_ylabel('Temperature (°C)')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    if len(gpu_monitor.gpu_utilization) > 0:\n",
    "        print(f\"\\n📊 GPU Training Statistics:\")\n",
    "        print(f\"Average GPU Utilization: {sum(gpu_monitor.gpu_utilization)/len(gpu_monitor.gpu_utilization):.1f}%\")\n",
    "        print(f\"Peak GPU Utilization: {max(gpu_monitor.gpu_utilization):.1f}%\")\n",
    "        print(f\"Average GPU Memory: {sum(gpu_monitor.gpu_memory)/len(gpu_monitor.gpu_memory):.1f}%\")\n",
    "        print(f\"Peak GPU Memory: {max(gpu_monitor.gpu_memory):.1f}%\")\n",
    "        print(f\"Average GPU Temperature: {sum(gpu_monitor.gpu_temperature)/len(gpu_monitor.gpu_temperature):.1f}°C\")\n",
    "        print(f\"Peak GPU Temperature: {max(gpu_monitor.gpu_temperature):.1f}°C\")\n",
    "        print(f\"Training Duration: {times[-1]:.2f} minutes\")\n",
    "else:\n",
    "    # Hide unused subplots if no GPU monitoring data\n",
    "    for i in range(1, 4):\n",
    "        axes.flat[i].set_visible(False)\n",
    "    axes[0, 0].set_position([0.1, 0.1, 0.8, 0.8])  # Make loss plot larger\n",
    "    print(\"⚠ No GPU monitoring data available\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Additional GPU Monitoring Utilities\n",
    "\n",
    "def watch_gpu_realtime(duration_seconds=30, interval=1.0):\n",
    "    \"\"\"\n",
    "    Real-time GPU monitoring for specified duration\n",
    "    Useful for monitoring GPU during training in another cell\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Monitoring GPU for {duration_seconds} seconds...\")\n",
    "    print(\"Time(s) | GPU Util | GPU Mem | GPU Temp\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < duration_seconds:\n",
    "        current_time = time.time() - start_time\n",
    "        gpu_util, gpu_mem, gpu_temp = gpu_monitor.get_gpu_stats()\n",
    "        print(f\"{current_time:6.1f} | {gpu_util:7.1f}% | {gpu_mem:6.1f}% | {gpu_temp:7.1f}°C\")\n",
    "        time.sleep(interval)\n",
    "\n",
    "def get_gpu_memory_usage():\n",
    "    \"\"\"Get detailed GPU memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9  # GB\n",
    "        cached = torch.cuda.memory_reserved() / 1e9      # GB\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1e9  # GB\n",
    "        \n",
    "        print(f\"💾 GPU Memory Usage:\")\n",
    "        print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "        print(f\"  Cached:    {cached:.2f} GB\") \n",
    "        print(f\"  Total:     {total:.2f} GB\")\n",
    "        print(f\"  Usage:     {(allocated/total)*100:.1f}%\")\n",
    "        \n",
    "        return allocated, cached, total\n",
    "    else:\n",
    "        print(\"❌ No GPU available\")\n",
    "        return 0, 0, 0\n",
    "\n",
    "def profile_model_memory(model, input_shape=(1, 1, 28, 28)):\n",
    "    \"\"\"Profile memory usage of model forward pass\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()  # Clear cache\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        \n",
    "        # Memory before model creation\n",
    "        baseline = torch.cuda.memory_allocated()\n",
    "        \n",
    "        # Create dummy input\n",
    "        dummy_input = torch.randn(input_shape).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            _ = model(dummy_input)\n",
    "        \n",
    "        peak_memory = torch.cuda.max_memory_allocated()\n",
    "        current_memory = torch.cuda.memory_allocated()\n",
    "        \n",
    "        print(f\"🧠 Model Memory Profile:\")\n",
    "        print(f\"  Baseline:     {baseline/1e6:.1f} MB\")\n",
    "        print(f\"  After Forward: {current_memory/1e6:.1f} MB\")\n",
    "        print(f\"  Peak Usage:   {peak_memory/1e6:.1f} MB\")\n",
    "        print(f\"  Model Size:   {(current_memory - baseline)/1e6:.1f} MB\")\n",
    "        \n",
    "        return (current_memory - baseline) / 1e6\n",
    "    else:\n",
    "        print(\"❌ No GPU available for profiling\")\n",
    "        return 0\n",
    "\n",
    "# Show current GPU status\n",
    "print(\"🖥️  Current GPU Status:\")\n",
    "get_gpu_memory_usage()\n",
    "\n",
    "# Usage examples:\n",
    "print(\"\\n📖 GPU Monitoring Usage:\")\n",
    "print(\"1. gpu_monitor.start_monitoring()     # Start background monitoring\")\n",
    "print(\"2. # Run your training here...\")\n",
    "print(\"3. gpu_monitor.stop_monitoring()      # Stop monitoring\") \n",
    "print(\"4. gpu_monitor.plot_stats()           # Plot monitoring results\")\n",
    "print(\"5. watch_gpu_realtime(30)             # Watch GPU for 30 seconds\")\n",
    "print(\"6. profile_model_memory(model)        # Profile model memory usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56488eb3",
   "metadata": {},
   "source": [
    "## 4. Visualize Latent Space (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(model, test_loader, device, num_samples=2000):\n",
    "    \"\"\"Plot the 2D latent space representation\"\"\"\n",
    "    model.eval()\n",
    "    latents = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data = data.to(device)\n",
    "            mu, _ = model.encoder(data)\n",
    "            latents.append(mu.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "            \n",
    "            if len(latents) * data.size(0) >= num_samples:\n",
    "                break\n",
    "    \n",
    "    latents = np.concatenate(latents, axis=0)[:num_samples]\n",
    "    labels = np.concatenate(labels, axis=0)[:num_samples]\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter = plt.scatter(latents[:, 0], latents[:, 1], c=labels, cmap='tab10', alpha=0.6)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title('2D Latent Space Representation (Color = Digit Class)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return latents, labels\n",
    "\n",
    "latents, labels = plot_latent_space(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e133d24",
   "metadata": {},
   "source": [
    "## 5. Implement Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialAttacks:\n",
    "    \"\"\"Class containing various adversarial attack methods for VAEs\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def fgsm_attack(model, data, target, epsilon):\n",
    "        \"\"\"\n",
    "        Fast Gradient Sign Method (FGSM) attack\n",
    "        \n",
    "        Args:\n",
    "            model: VAE model\n",
    "            data: input data\n",
    "            target: target data (for reconstruction loss)\n",
    "            epsilon: perturbation magnitude\n",
    "        \"\"\"\n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Enable gradient computation for input\n",
    "        data.requires_grad = True\n",
    "        \n",
    "        # Forward pass\n",
    "        recon_data, mu, logvar = model(data)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = vae_loss(recon_data, target, mu, logvar)\n",
    "        \n",
    "        # Zero gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Get gradient sign\n",
    "        data_grad = data.grad.data\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        \n",
    "        # Create adversarial example\n",
    "        perturbed_data = data + epsilon * sign_data_grad\n",
    "        perturbed_data = torch.clamp(perturbed_data, 0, 1)\n",
    "        \n",
    "        return perturbed_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def pgd_attack(model, data, target, epsilon, alpha, num_iter):\n",
    "        \"\"\"\n",
    "        Projected Gradient Descent (PGD) attack\n",
    "        \n",
    "        Args:\n",
    "            model: VAE model\n",
    "            data: input data\n",
    "            target: target data\n",
    "            epsilon: maximum perturbation\n",
    "            alpha: step size\n",
    "            num_iter: number of iterations\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        # Initialize perturbation\n",
    "        delta = torch.zeros_like(data).uniform_(-epsilon, epsilon)\n",
    "        delta.requires_grad = True\n",
    "        \n",
    "        for i in range(num_iter):\n",
    "            # Forward pass with perturbation\n",
    "            perturbed_data = data + delta\n",
    "            recon_data, mu, logvar = model(perturbed_data)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = vae_loss(recon_data, target, mu, logvar)\n",
    "            \n",
    "            # Calculate gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update perturbation\n",
    "            delta.data = delta.data + alpha * delta.grad.data.sign()\n",
    "            delta.data = torch.clamp(delta.data, -epsilon, epsilon)\n",
    "            delta.data = torch.clamp(data + delta.data, 0, 1) - data\n",
    "            \n",
    "            # Zero gradients\n",
    "            delta.grad.zero_()\n",
    "        \n",
    "        return data + delta\n",
    "    \n",
    "    @staticmethod\n",
    "    def latent_space_attack(model, data, epsilon, target_latent=None):\n",
    "        \"\"\"\n",
    "        Attack in latent space by perturbing encoded representations\n",
    "        \n",
    "        Args:\n",
    "            model: VAE model\n",
    "            data: input data\n",
    "            epsilon: perturbation magnitude in latent space\n",
    "            target_latent: target latent representation (optional)\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        # Encode to latent space\n",
    "        mu, logvar = model.encoder(data)\n",
    "        z = model.reparameterize(mu, logvar)\n",
    "        \n",
    "        if target_latent is not None:\n",
    "            # Move towards target latent representation\n",
    "            direction = (target_latent - z).sign()\n",
    "            perturbed_z = z + epsilon * direction\n",
    "        else:\n",
    "            # Random perturbation in latent space\n",
    "            noise = torch.randn_like(z)\n",
    "            perturbed_z = z + epsilon * noise\n",
    "        \n",
    "        # Decode back to image space\n",
    "        adversarial_recon = model.decoder(perturbed_z)\n",
    "        \n",
    "        return adversarial_recon, z, perturbed_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce955d6",
   "metadata": {},
   "source": [
    "## 6. Demonstrate Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd32faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test samples for attacks\n",
    "test_iter = iter(test_loader)\n",
    "test_data, test_labels = next(test_iter)\n",
    "test_data = test_data[:8].to(device)  # Use first 8 samples\n",
    "\n",
    "# Initialize attack methods\n",
    "attacks = AdversarialAttacks()\n",
    "\n",
    "# Show original images\n",
    "fig, axes = plt.subplots(1, 8, figsize=(16, 2))\n",
    "for i in range(8):\n",
    "    axes[i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[i].set_title(f'Original {i}')\n",
    "    axes[i].axis('off')\n",
    "plt.suptitle('Original Test Images')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a5b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM Attack - Comprehensive Analysis\n",
    "print(\"\\n=== FGSM Attack - Complete Pipeline ===\")\n",
    "epsilon_fgsm = 0.1\n",
    "fgsm_adversarial = attacks.fgsm_attack(model, test_data, test_data, epsilon=epsilon_fgsm)\n",
    "\n",
    "# Get reconstructions\n",
    "with torch.no_grad():\n",
    "    original_recon, _, _ = model(test_data)\n",
    "    adversarial_recon, _, _ = model(fgsm_adversarial)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(6, 8, figsize=(16, 12))\n",
    "row_labels = [\n",
    "    'Original Input',\n",
    "    'Original Reconstruction', \n",
    "    'Adversarial Input',\n",
    "    'Adversarial Reconstruction',\n",
    "    'Input Difference (x10)',\n",
    "    'Reconstruction Difference (x10)'\n",
    "]\n",
    "\n",
    "for i in range(8):\n",
    "    # Row 1: Original inputs\n",
    "    axes[0, i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Sample {i}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Original reconstructions\n",
    "    axes[1, i].imshow(original_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Row 3: Adversarial inputs (epsilon-perturbed)\n",
    "    axes[2, i].imshow(fgsm_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[2, i].axis('off')\n",
    "    \n",
    "    # Row 4: Adversarial reconstructions\n",
    "    axes[3, i].imshow(adversarial_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[3, i].axis('off')\n",
    "    \n",
    "    # Row 5: Input differences (original vs adversarial, amplified)\n",
    "    input_diff = (fgsm_adversarial[i] - test_data[i]).detach().cpu().squeeze()\n",
    "    axes[4, i].imshow(input_diff * 10, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[4, i].axis('off')\n",
    "    \n",
    "    # Row 6: Reconstruction differences (original recon vs adversarial recon, amplified)\n",
    "    recon_diff = (adversarial_recon[i] - original_recon[i]).detach().cpu().squeeze()\n",
    "    axes[5, i].imshow(recon_diff * 10, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[5, i].axis('off')\n",
    "\n",
    "# Add row labels\n",
    "for i, label in enumerate(row_labels):\n",
    "    axes[i, 0].set_ylabel(label, rotation=90, labelpad=50, fontsize=10, ha='center')\n",
    "\n",
    "plt.suptitle(f'FGSM Attack Analysis (ε={epsilon_fgsm})', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display statistics\n",
    "input_perturbation = (fgsm_adversarial - test_data).detach().cpu()\n",
    "recon_perturbation = (adversarial_recon - original_recon).detach().cpu()\n",
    "\n",
    "print(f\"\\n📊 FGSM Attack Statistics:\")\n",
    "print(f\"Input Perturbation:\")\n",
    "print(f\"  L2 norm: {torch.norm(input_perturbation).item():.6f}\")\n",
    "print(f\"  L∞ norm: {torch.max(torch.abs(input_perturbation)).item():.6f}\")\n",
    "print(f\"  Mean absolute: {torch.mean(torch.abs(input_perturbation)).item():.6f}\")\n",
    "\n",
    "print(f\"\\nReconstruction Perturbation:\")\n",
    "print(f\"  L2 norm: {torch.norm(recon_perturbation).item():.6f}\")\n",
    "print(f\"  L∞ norm: {torch.max(torch.abs(recon_perturbation)).item():.6f}\")\n",
    "print(f\"  Mean absolute: {torch.mean(torch.abs(recon_perturbation)).item():.6f}\")\n",
    "\n",
    "print(f\"\\nAmplification Factor: {torch.norm(recon_perturbation).item() / torch.norm(input_perturbation).item():.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11dbd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD Attack - Comprehensive Analysis\n",
    "print(\"\\n=== PGD Attack - Complete Pipeline ===\")\n",
    "epsilon_pgd = 0.1\n",
    "alpha = 0.01\n",
    "num_iter = 20\n",
    "\n",
    "pgd_adversarial = attacks.pgd_attack(model, test_data, test_data, \n",
    "                                   epsilon=epsilon_pgd, alpha=alpha, num_iter=num_iter)\n",
    "\n",
    "# Get reconstructions\n",
    "with torch.no_grad():\n",
    "    original_recon, _, _ = model(test_data)\n",
    "    pgd_adversarial_recon, _, _ = model(pgd_adversarial)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(6, 8, figsize=(16, 12))\n",
    "row_labels = [\n",
    "    'Original Input',\n",
    "    'Original Reconstruction', \n",
    "    'PGD Adversarial Input',\n",
    "    'PGD Adversarial Reconstruction',\n",
    "    'Input Difference (x10)',\n",
    "    'Reconstruction Difference (x10)'\n",
    "]\n",
    "\n",
    "for i in range(8):\n",
    "    # Row 1: Original inputs\n",
    "    axes[0, i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Sample {i}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Original reconstructions\n",
    "    axes[1, i].imshow(original_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Row 3: PGD adversarial inputs\n",
    "    axes[2, i].imshow(pgd_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[2, i].axis('off')\n",
    "    \n",
    "    # Row 4: PGD adversarial reconstructions\n",
    "    axes[3, i].imshow(pgd_adversarial_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[3, i].axis('off')\n",
    "    \n",
    "    # Row 5: Input differences (original vs PGD adversarial, amplified)\n",
    "    input_diff = (pgd_adversarial[i] - test_data[i]).detach().cpu().squeeze()\n",
    "    axes[4, i].imshow(input_diff * 10, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[4, i].axis('off')\n",
    "    \n",
    "    # Row 6: Reconstruction differences (original recon vs PGD adversarial recon, amplified)\n",
    "    recon_diff = (pgd_adversarial_recon[i] - original_recon[i]).detach().cpu().squeeze()\n",
    "    axes[5, i].imshow(recon_diff * 10, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[5, i].axis('off')\n",
    "\n",
    "# Add row labels\n",
    "for i, label in enumerate(row_labels):\n",
    "    axes[i, 0].set_ylabel(label, rotation=90, labelpad=50, fontsize=10, ha='center')\n",
    "\n",
    "plt.suptitle(f'PGD Attack Analysis (ε={epsilon_pgd}, α={alpha}, iter={num_iter})', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display statistics\n",
    "input_perturbation_pgd = (pgd_adversarial - test_data).detach().cpu()\n",
    "recon_perturbation_pgd = (pgd_adversarial_recon - original_recon).detach().cpu()\n",
    "\n",
    "print(f\"\\n📊 PGD Attack Statistics:\")\n",
    "print(f\"Input Perturbation:\")\n",
    "print(f\"  L2 norm: {torch.norm(input_perturbation_pgd).item():.6f}\")\n",
    "print(f\"  L∞ norm: {torch.max(torch.abs(input_perturbation_pgd)).item():.6f}\")\n",
    "print(f\"  Mean absolute: {torch.mean(torch.abs(input_perturbation_pgd)).item():.6f}\")\n",
    "\n",
    "print(f\"\\nReconstruction Perturbation:\")\n",
    "print(f\"  L2 norm: {torch.norm(recon_perturbation_pgd).item():.6f}\")\n",
    "print(f\"  L∞ norm: {torch.max(torch.abs(recon_perturbation_pgd)).item():.6f}\")\n",
    "print(f\"  Mean absolute: {torch.mean(torch.abs(recon_perturbation_pgd)).item():.6f}\")\n",
    "\n",
    "print(f\"\\nAmplification Factor: {torch.norm(recon_perturbation_pgd).item() / torch.norm(input_perturbation_pgd).item():.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ddda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare FGSM vs PGD Attack Effects\n",
    "print(\"\\n=== FGSM vs PGD Comparison ===\")\n",
    "\n",
    "# Select first 4 samples for detailed comparison\n",
    "num_samples = 4\n",
    "fig, axes = plt.subplots(7, num_samples, figsize=(12, 14))\n",
    "\n",
    "comparison_labels = [\n",
    "    'Original Input',\n",
    "    'Original Reconstruction',\n",
    "    'FGSM Adversarial',\n",
    "    'FGSM Reconstruction', \n",
    "    'PGD Adversarial',\n",
    "    'PGD Reconstruction',\n",
    "    'FGSM vs PGD Diff (x5)'\n",
    "]\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Row 1: Original inputs\n",
    "    axes[0, i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Sample {i}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Original reconstructions\n",
    "    axes[1, i].imshow(original_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Row 3: FGSM adversarial inputs\n",
    "    axes[2, i].imshow(fgsm_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[2, i].axis('off')\n",
    "    \n",
    "    # Row 4: FGSM adversarial reconstructions\n",
    "    axes[3, i].imshow(adversarial_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[3, i].axis('off')\n",
    "    \n",
    "    # Row 5: PGD adversarial inputs\n",
    "    axes[4, i].imshow(pgd_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[4, i].axis('off')\n",
    "    \n",
    "    # Row 6: PGD adversarial reconstructions\n",
    "    axes[5, i].imshow(pgd_adversarial_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[5, i].axis('off')\n",
    "    \n",
    "    # Row 7: Difference between FGSM and PGD adversarial inputs\n",
    "    fgsm_vs_pgd_diff = (fgsm_adversarial[i] - pgd_adversarial[i]).detach().cpu().squeeze()\n",
    "    axes[6, i].imshow(fgsm_vs_pgd_diff * 5, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[6, i].axis('off')\n",
    "\n",
    "# Add row labels\n",
    "for i, label in enumerate(comparison_labels):\n",
    "    axes[i, 0].set_ylabel(label, rotation=90, labelpad=40, fontsize=9, ha='center')\n",
    "\n",
    "plt.suptitle('FGSM vs PGD Attack Comparison', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.18)\n",
    "plt.show()\n",
    "\n",
    "# Quantitative comparison\n",
    "print(f\"\\n📈 Attack Method Comparison:\")\n",
    "print(f\"{'Metric':<25} {'FGSM':<12} {'PGD':<12} {'Ratio (PGD/FGSM)':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "fgsm_input_l2 = torch.norm(input_perturbation).item()\n",
    "pgd_input_l2 = torch.norm(input_perturbation_pgd).item()\n",
    "print(f\"{'Input L2 Perturbation':<25} {fgsm_input_l2:<12.6f} {pgd_input_l2:<12.6f} {pgd_input_l2/fgsm_input_l2:<15.2f}\")\n",
    "\n",
    "fgsm_recon_l2 = torch.norm(recon_perturbation).item()\n",
    "pgd_recon_l2 = torch.norm(recon_perturbation_pgd).item()\n",
    "print(f\"{'Recon L2 Perturbation':<25} {fgsm_recon_l2:<12.6f} {pgd_recon_l2:<12.6f} {pgd_recon_l2/fgsm_recon_l2:<15.2f}\")\n",
    "\n",
    "fgsm_input_linf = torch.max(torch.abs(input_perturbation)).item()\n",
    "pgd_input_linf = torch.max(torch.abs(input_perturbation_pgd)).item()\n",
    "print(f\"{'Input L∞ Perturbation':<25} {fgsm_input_linf:<12.6f} {pgd_input_linf:<12.6f} {pgd_input_linf/fgsm_input_linf:<15.2f}\")\n",
    "\n",
    "fgsm_recon_linf = torch.max(torch.abs(recon_perturbation)).item()\n",
    "pgd_recon_linf = torch.max(torch.abs(recon_perturbation_pgd)).item()\n",
    "print(f\"{'Recon L∞ Perturbation':<25} {fgsm_recon_linf:<12.6f} {pgd_recon_linf:<12.6f} {pgd_recon_linf/fgsm_recon_linf:<15.2f}\")\n",
    "\n",
    "# Check if attacks are different\n",
    "attack_similarity = F.mse_loss(fgsm_adversarial, pgd_adversarial).item()\n",
    "print(f\"\\n🔍 Attack Similarity (MSE between FGSM and PGD adversarial inputs): {attack_similarity:.6f}\")\n",
    "if attack_similarity < 1e-6:\n",
    "    print(\"⚠️  Warning: FGSM and PGD attacks produced nearly identical results!\")\n",
    "else:\n",
    "    print(\"✓ FGSM and PGD attacks produced different adversarial examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357dff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Space Attack\n",
    "print(\"\\n=== Latent Space Attack ===\")\n",
    "epsilon_latent = 2.0\n",
    "\n",
    "latent_adversarial, orig_latent, perturbed_latent = attacks.latent_space_attack(\n",
    "    model, test_data, epsilon=epsilon_latent)\n",
    "\n",
    "# Get original reconstructions for comparison\n",
    "with torch.no_grad():\n",
    "    original_recon, _, _ = model(test_data)\n",
    "\n",
    "# Visualize latent space attack results\n",
    "fig, axes = plt.subplots(3, 8, figsize=(16, 6))\n",
    "for i in range(8):\n",
    "    # Original\n",
    "    axes[0, i].imshow(test_data[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Original {i}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Original reconstruction\n",
    "    axes[1, i].imshow(original_recon[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[1, i].set_title(f'Original Recon')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Latent attack result\n",
    "    axes[2, i].imshow(latent_adversarial[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[2, i].set_title(f'Latent Attack')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.suptitle(f'Latent Space Attack Results (ε={epsilon_latent})')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show latent space perturbations\n",
    "print(f\"Latent space perturbation magnitude: {torch.norm(perturbed_latent - orig_latent).item():.6f}\")\n",
    "print(f\"Original latent mean: {orig_latent.mean(dim=0).detach().cpu().numpy()}\")\n",
    "print(f\"Perturbed latent mean: {perturbed_latent.mean(dim=0).detach().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e08762",
   "metadata": {},
   "source": [
    "## 7. Evaluate Attack Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack_effectiveness(model, original, adversarial, attack_name):\n",
    "    \"\"\"Evaluate the effectiveness of adversarial attacks\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Reconstruct original\n",
    "        recon_orig, mu_orig, logvar_orig = model(original)\n",
    "        \n",
    "        # Reconstruct adversarial\n",
    "        recon_adv, mu_adv, logvar_adv = model(adversarial)\n",
    "        \n",
    "        # Calculate reconstruction errors\n",
    "        orig_error = F.mse_loss(recon_orig, original).item()\n",
    "        adv_error = F.mse_loss(recon_adv, adversarial).item()\n",
    "        \n",
    "        # Calculate latent space distances\n",
    "        latent_distance = F.mse_loss(mu_orig, mu_adv).item()\n",
    "        \n",
    "        # Calculate input perturbation\n",
    "        input_perturbation = F.mse_loss(original, adversarial).item()\n",
    "        \n",
    "        print(f\"\\n=== {attack_name} Effectiveness ===\")\n",
    "        print(f\"Original Reconstruction Error: {orig_error:.6f}\")\n",
    "        print(f\"Adversarial Reconstruction Error: {adv_error:.6f}\")\n",
    "        print(f\"Latent Space Distance: {latent_distance:.6f}\")\n",
    "        print(f\"Input Perturbation (MSE): {input_perturbation:.6f}\")\n",
    "        \n",
    "        return orig_error, adv_error, latent_distance, input_perturbation\n",
    "\n",
    "# Evaluate all attacks\n",
    "fgsm_results = evaluate_attack_effectiveness(model, test_data, fgsm_adversarial, \"FGSM\")\n",
    "pgd_results = evaluate_attack_effectiveness(model, test_data, pgd_adversarial, \"PGD\")\n",
    "\n",
    "# For latent attack, compare original reconstruction vs latent attack result\n",
    "with torch.no_grad():\n",
    "    orig_recon, orig_mu, orig_logvar = model(test_data)\n",
    "    latent_mse = F.mse_loss(orig_recon, latent_adversarial).item()\n",
    "    print(f\"\\n=== Latent Space Attack Effectiveness ===\")\n",
    "    print(f\"Original vs Latent Attack Reconstruction MSE: {latent_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c622df4",
   "metadata": {},
   "source": [
    "## 8. Robustness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test robustness across different epsilon values\n",
    "print(\"\\n=== Robustness Analysis ===\")\n",
    "epsilons = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "fgsm_errors = []\n",
    "pgd_errors = []\n",
    "perturbation_magnitudes = []\n",
    "\n",
    "for eps in tqdm(epsilons, desc=\"Testing epsilon values\"):\n",
    "    # FGSM\n",
    "    fgsm_adv = attacks.fgsm_attack(model, test_data, test_data, epsilon=eps)\n",
    "    _, fgsm_error, _, fgsm_pert = evaluate_attack_effectiveness(model, test_data, fgsm_adv, f\"FGSM-{eps}\")\n",
    "    fgsm_errors.append(fgsm_error)\n",
    "    \n",
    "    # PGD\n",
    "    pgd_adv = attacks.pgd_attack(model, test_data, test_data, epsilon=eps, alpha=0.01, num_iter=10)\n",
    "    _, pgd_error, _, pgd_pert = evaluate_attack_effectiveness(model, test_data, pgd_adv, f\"PGD-{eps}\")\n",
    "    pgd_errors.append(pgd_error)\n",
    "    \n",
    "    perturbation_magnitudes.append(eps)\n",
    "\n",
    "# Plot robustness curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epsilons, fgsm_errors, 'o-', label='FGSM', linewidth=2)\n",
    "plt.plot(epsilons, pgd_errors, 's-', label='PGD', linewidth=2)\n",
    "plt.xlabel('Epsilon (Perturbation Magnitude)')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('VAE Robustness vs Perturbation Magnitude')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Test different latent space perturbation magnitudes\n",
    "latent_epsilons = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "latent_errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    orig_recon, _, _ = model(test_data)\n",
    "\n",
    "for eps in latent_epsilons:\n",
    "    latent_adv, _, _ = attacks.latent_space_attack(model, test_data, epsilon=eps)\n",
    "    error = F.mse_loss(orig_recon, latent_adv).item()\n",
    "    latent_errors.append(error)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(latent_epsilons, latent_errors, '^-', color='green', linewidth=2)\n",
    "plt.xlabel('Latent Space Perturbation Magnitude')\n",
    "plt.ylabel('Reconstruction Difference (MSE)')\n",
    "plt.title('Latent Space Attack Effectiveness')\n",
    "plt.grid(True)\n",
    "\n",
    "# Compare attack methods\n",
    "plt.subplot(1, 3, 3)\n",
    "methods = ['Original', 'FGSM\\n(ε=0.1)', 'PGD\\n(ε=0.1)', 'Latent\\n(ε=2.0)']\n",
    "errors = [fgsm_results[0], fgsm_results[1], pgd_results[1], latent_mse]\n",
    "colors = ['blue', 'red', 'orange', 'green']\n",
    "\n",
    "bars = plt.bar(methods, errors, color=colors, alpha=0.7)\n",
    "plt.ylabel('Reconstruction Error / MSE')\n",
    "plt.title('Attack Method Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, error in zip(bars, errors):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.0001, \n",
    "             f'{error:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8d0715",
   "metadata": {},
   "source": [
    "## 9. Visualize Latent Space Perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e71041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how attacks affect the latent space\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get latent representations\n",
    "    mu_orig, _ = model.encoder(test_data[:4])\n",
    "    mu_fgsm, _ = model.encoder(fgsm_adversarial[:4])\n",
    "    mu_pgd, _ = model.encoder(pgd_adversarial[:4])\n",
    "\n",
    "# Plot latent space movements\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "for i in range(4):\n",
    "    # Original point\n",
    "    plt.scatter(mu_orig[i, 0].cpu(), mu_orig[i, 1].cpu(), \n",
    "               color=colors[i], s=100, marker='o', label=f'Original {i}' if i < 4 else \"\")\n",
    "    \n",
    "    # FGSM point\n",
    "    plt.scatter(mu_fgsm[i, 0].cpu(), mu_fgsm[i, 1].cpu(), \n",
    "               color=colors[i], s=100, marker='x', alpha=0.7)\n",
    "    \n",
    "    # PGD point\n",
    "    plt.scatter(mu_pgd[i, 0].cpu(), mu_pgd[i, 1].cpu(), \n",
    "               color=colors[i], s=100, marker='^', alpha=0.7)\n",
    "    \n",
    "    # Draw arrows showing movement\n",
    "    plt.arrow(mu_orig[i, 0].cpu(), mu_orig[i, 1].cpu(),\n",
    "             mu_fgsm[i, 0].cpu() - mu_orig[i, 0].cpu(),\n",
    "             mu_fgsm[i, 1].cpu() - mu_orig[i, 1].cpu(),\n",
    "             color=colors[i], alpha=0.5, head_width=0.1, linestyle='--')\n",
    "    \n",
    "    plt.arrow(mu_orig[i, 0].cpu(), mu_orig[i, 1].cpu(),\n",
    "             mu_pgd[i, 0].cpu() - mu_orig[i, 0].cpu(),\n",
    "             mu_pgd[i, 1].cpu() - mu_orig[i, 1].cpu(),\n",
    "             color=colors[i], alpha=0.5, head_width=0.1, linestyle='-')\n",
    "\n",
    "# Create custom legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='black', markersize=8, label='Original'),\n",
    "    Line2D([0], [0], marker='x', color='w', markerfacecolor='black', markersize=8, label='FGSM'),\n",
    "    Line2D([0], [0], marker='^', color='w', markerfacecolor='black', markersize=8, label='PGD'),\n",
    "    Line2D([0], [0], color='black', linestyle='--', label='FGSM Movement'),\n",
    "    Line2D([0], [0], color='black', linestyle='-', label='PGD Movement')\n",
    "]\n",
    "\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.title('Latent Space Perturbations from Adversarial Attacks')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814084bb",
   "metadata": {},
   "source": [
    "## 10. Defense Mechanisms (Bonus)\n",
    "\n",
    "Here are some strategies to improve VAE robustness against adversarial attacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd7e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_training_step(model, data, optimizer, epsilon=0.1, alpha=0.01):\n",
    "    \"\"\"\n",
    "    Single step of adversarial training\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # Generate adversarial examples\n",
    "    model.eval()\n",
    "    adv_data = AdversarialAttacks.fgsm_attack(model, data, data, epsilon)\n",
    "    model.train()\n",
    "    \n",
    "    # Train on both clean and adversarial data\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Clean loss\n",
    "    recon_clean, mu_clean, logvar_clean = model(data)\n",
    "    clean_loss = vae_loss(recon_clean, data, mu_clean, logvar_clean)\n",
    "    \n",
    "    # Adversarial loss\n",
    "    recon_adv, mu_adv, logvar_adv = model(adv_data)\n",
    "    adv_loss = vae_loss(recon_adv, adv_data, mu_adv, logvar_adv)\n",
    "    \n",
    "    # Combined loss\n",
    "    total_loss = 0.5 * clean_loss + 0.5 * adv_loss\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return total_loss.item()\n",
    "\n",
    "print(\"Defense Strategies for VAEs:\")\n",
    "print(\"1. Adversarial Training: Train on both clean and adversarial examples\")\n",
    "print(\"2. Input Preprocessing: Add noise or apply transformations\")\n",
    "print(\"3. Regularization: Increase β in β-VAE to enforce stronger regularization\")\n",
    "print(\"4. Ensemble Methods: Use multiple VAE models and average predictions\")\n",
    "print(\"5. Certified Defenses: Use techniques like randomized smoothing\")\n",
    "\n",
    "# Example: Train a model with higher β for better regularization\n",
    "robust_model = VAE(latent_dim=2)\n",
    "print(\"\\nTraining a more robust VAE with β=5.0...\")\n",
    "robust_losses = train_vae(robust_model, train_loader, epochs=5, beta=5.0)\n",
    "\n",
    "# Test robustness of the new model\n",
    "print(\"\\nTesting robustness of β-VAE:\")\n",
    "robust_fgsm = attacks.fgsm_attack(robust_model, test_data, test_data, epsilon=0.1)\n",
    "evaluate_attack_effectiveness(robust_model, test_data, robust_fgsm, \"Robust β-VAE FGSM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dbe769",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated several key concepts in adversarial attacks on VAEs:\n",
    "\n",
    "### Attack Methods:\n",
    "1. **FGSM (Fast Gradient Sign Method)**: Single-step attack using gradient sign\n",
    "2. **PGD (Projected Gradient Descent)**: Multi-step iterative attack\n",
    "3. **Latent Space Attack**: Perturbations in the encoded latent representation\n",
    "\n",
    "### Key Findings:\n",
    "- VAEs are vulnerable to adversarial perturbations in both input and latent spaces\n",
    "- Small input perturbations can cause significant changes in latent representations\n",
    "- The 2D latent space makes visualization of attack effects possible\n",
    "- Different attack methods have varying effectiveness\n",
    "\n",
    "### Defense Strategies:\n",
    "- Adversarial training with mixed clean/adversarial data\n",
    "- Stronger regularization (higher β in β-VAE)\n",
    "- Input preprocessing and ensemble methods\n",
    "- Certified defense techniques\n",
    "\n",
    "This framework can be extended to other autoencoder architectures and datasets to study adversarial robustness in generative models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
